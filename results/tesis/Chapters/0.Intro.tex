\chapter*{Introducción}
\addcontentsline{toc}{chapter}{Introducción}

% La introducción no cuenta como primer capítulo

\noindent El rápido crecimiento de los datos en los últimos años ha generado la necesidad de crear nuevos sistemas que tengan la capacidad de coleccionar, administrar, procesar y entregar datos que puedan resolver problemas del día a día \cite{seagate}. Los avances en el cómputo han permitido lograrlo. Sin embargo, el gran avance en los sistemas de almacenamiento combinados con la desaceleración en el desarrollo de procesadores más rápidos ha obligado a usar el cómputo en paralelo para poder procesar la enorme cantidad de datos creada cada día \cite{sparkguide}. \textit{Dask} y \textit{Spark} son dos herramientas populares que combinan la ejecución en paralelo, cómputo en memoria, evaluación perezosa y calendarizadores dinámicos que les permiten atender problemas de \textit{Big Data} \cite{dask-spark-neuroimaging}.

\textit{Spark} es un motor de cómputo con bibliotecas para procesamiento de datos en paralelo que puede funcionar en un equipo local o escalar a un grupo de computadoras. Soporta múltiples lenguajes de programación como \textit{Python} (aunque está escrito en \textit{Scala}) y es utilizado para aplicaciones como \textit{SQL}, \textit{streaming} y \textit{machine learning} \cite{sparkguide}. Además tiene integración con múltiples sistemas de procesamiento y almacenamiento y tiene desempeño comparable a herramientas diseñadas para propósitos específicos \cite{sparkberkeley}. Esto la convierte en una herramienta versátil y competitiva para el procesamiento de datos. 

\textit{Dask} es una biblioteca desarrollada totalmente en \textit{Python} para cómputo en paralelo que extiende las capacidades de herramientas populares como \textit{NumPy} y \textit{Pandas} a tareas que no caben en memoria o a ambientes distribuidos de cientos de máquinas. Además, cuenta con fuerte integración con proyectos existentes como \textit{Scikit-Learn} que le dan la capacidad de crear aplicaciones de \textit{machine learning} o procesamiento de datos \cite{daskdocs}.

El objetivo de este trabajo fue comparar el desempeño de la abstracción más popular (el \textit{DataFrame}) de ambas herramientas bajo diferentes condiciones para determinar bajo qué circunstancias una es superior a la otra. Para esto se ejecutaron diversas tareas que incluyeron agregaciones, cálculo de estadísticas, preparación de datos y una implementación del algoritmo \textit{Dijkstra}. Los \textit{frameworks} fueron probados en el conjunto de datos \textit{Reporting Carrier On-Time Performance (1987-present)} con un tamaño aproximado de 43 GB y las pruebas se ejecutaron en un ambiente local y en uno distribuido en la nube. También se incluye una sección para evaluar la experiencia de uso en cada \textit{framework}.

Este trabajo se estructura de la siguiente manera: En el primer capítulo, se hace una revisión de la literatura existente sobre la comparación de ambos \textit{frameworks} y se resumen sus conclusiones más importantes. El segundo capítulo aborda el marco teórico del trabajo, en el que se describe cada uno de los \textit{frameworks} y se explica el algoritmo de ruta mínima \textit{Dijkstra}. En el tercer capítulo, se describe la metodología que se siguió para la ejecución del experimento, describiendo los procesos seleccionados, los ambientes en los que se ejecutó y el conjunto de datos utilizado. El cuarto capítulo tiene como objetivo reportar los resultados de los experimentos y resaltar las conclusiones más importantes derivadas de los mismos. El siguiente capítulo hace un análisis cualitativo sobre la experiencia de implementación utilizando ambos \textit{frameworks}, abordando desde la instalación hasta la configuración de trabajos en cada uno de ellos. Por último, en el capítulo final, se resumen las conclusiones de la investigación y se sugieren temas en los que se podría ahondar como trabajo futuro.

\section*{Objetivo y motivación}

\noindent Al introducirme al mundo de \textit{Big Data}, tanto \textit{Dask} como \textit{Spark} se me presentaron como opciones evidentes para resolver mis tareas del día a día. Ambos \textit{frameworks} venían acompañados de múltiples recursos para consulta y de comunidades activas que hacían que su adopción fuera más sencilla. Sin embargo, las referencias que ayudaban a decidir qué herramienta se ajustaba mejor a mi caso de uso no eran numerosas y, en la mayoría de los casos, tampoco realizaban un análisis profundo. Además, las investigaciones que comparaban los \textit{frameworks}, usualmente se centraban en abstracciones de más bajo nivel que han perdido relevancia en la actualidad y rara vez mencionaban los más utilizados \textit{DataFrames}. Esto me motivó a realizar una investigación que pudiera ser una referencia para futuros implementadores que estén intentando decidir entre \textit{Dask} y \textit{Spark} considerando no sólo la capacidad de cada herramienta sino la experiencia de uso también.

Este trabajo busca obtener datos que permitan contrastar las capacidades de ambas herramientas al ser expuestas a diferentes tareas y condiciones que son comunes cuando se resuelven problemas de \textit{Big Data} y análisis de datos. Además, tiene el objetivo de identificar algunas de las características de cada una de ellas que determinan los resultados obtenidos. De esta forma, quienes consulten esta investigación tendrán más elementos para decidir entre ambas. Adicionalmente, el trabajo también aborda la experiencia de implementación, que es un aspecto que es más difícil de medir pero que también es muy importante y que no siempre es tomado en cuenta. De esta forma, el resultado buscado es exponer resultados que permitan ver las ventajas y desventajas de cada herramienta, así como algunos de los retos que se pueden encontrar al realizar una implementación con cada una de ellas.

\section*{Alcance}

Debido a las enormes capacidades de cada \textit{framework}, no es posible medirlos en cada una de ellas. Por esta razón, este trabajo se concentra en evaluar las siguientes 6 capacidades: robustez de la herramienta, tiempo de ejecución total, tiempo de cómputo, tiempo de escritura, tiempo de inicio de la ejecución y variación de tiempo registrado. Estas capacidades son puestas a prueba usando 8 distintos procesos que fueron probados con diferentes tamaños de muestra y en dos ambientes distintos: uno local y otro distribuido en la nube. El tamaño de las muestras estuvo entre 10,000 y 80 millones de registros y la implementación de ambos \textit{frameworks} se realizó utilizando sus \textit{APIs} para \textit{Python}. Además, también se incluyó una sección con las dificultades y ventajas encontradas durante la implementación de los procesos en cada herramienta para poder dar una referencia de la experiencia de uso de cada herramienta. Los resultados del trabajo se limitaron a la ejecución e implementación bajo estas condiciones, pero pretenden convertirse en una base para futuras investigaciones. Para facilitar a esto, en \cite{repo-spark-rita} se pueden consultar los recursos utilizados para el trabajo. Entre estos están archivos de código, muestras de datos y resultados obtenidos.


% Se sugiere que el primer párrafo de cada sección no tenga sangría: \noindent
