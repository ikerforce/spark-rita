\chapter{Revisión de literatura}

\noindent En esta sección se resumen las investigaciones que se han realizado previamente  

En \cite{comparative-evolution} se hace un análisis de 5 sistemas de \textit{Big Data} entre los cuales se incluyen los \textit{RDDs} de \textit{Spark} y los objetos \textit{futures} y \textit{delayed} de \textit{Dask}. En ambos casos, se trata de abstracciones de más bajo nivel que los \textit{DataFrames} que serán utilizados en esta investigación. El experimiento realizado en \cite{comparative-evolution} tiene un enfoque de procesamiento de imágenes y compara el desempeño de las herramientas en dos procesos y con 6 diferentes tamaños de datos y también en clústeres de 3 tamaños distintos. En el experimento se observa una duración similar entre \textit{Dask} y \textit{Spark} para el primero de los procesos y un desempeño superior de \textit{Dask} en el segundo proceso (en general, \textit{Dask} fue un $14\%$ más rápido que \textit{Spark}), no obstante, \textit{Dask} presenta problemas de falta de memoria para que le impiden completar un proceso con el conjunto de datos de mayor tamaño. Además, con los distintos tamaños de clústeres, \textit{Dask} tiene un desempeño ligeramente mejor que se incrementa junto con el tamaño del clúster. No obstante, para el clúster más pequeño, \textit{Dask} presenta errores de memoria que le impiden completar el proceso. Además, la investigación hace un análisis cualitativo para evaluar la facilidad y efectividad de implementación utilizando cada una de las herramientas y destaca ventajas de \textit{Spark} como el gran tamaño de su comunidad y documentación disponible y la facilidad de implementar funciones de \textit{Python} mediante \textit{User Defined Functions}, además, menciona desventajas como la dificultad de implementación para desarrolladores no familiarizados con la programación funcional, la falta de \textit{caching} de forma predeterminada que puede resultar en recalcular resultados de forma innecesaria y finalmente advierte que afinar los parámetros para el uso de recursos no es trivial. Por otro lado, para \textit{Dask}, destaca como ventajas su fácil instalación y despliegue, su compatibilidad con bibliotecas externas de \textit{Python} y la similitud de su interfaz con otras herramientas populares. Sin embargo, menciona desventajas como la construcción no trivial de la gráfica de ejecución debido a las múltiples formas de hacerlo, la dificultad de encontrar errores en el código (\textit{debugging}) y la inestabilidad que presenta para ejecutar algunos procesos.

Una investigación posterior (\cite{dask-spark-neuroimaging}) hace un comparativo entre \textit{Dask} y \textit{Spark} enfocándose también en procesamiento de imágenes y mediante el uso de abstracciones de más bajo nivel para ambas herramientas (\textit{Futures, Bags} y \textit{Delayed} para \textit{Dask} y \textit{RDDs} para \textit{Spark}). La investigación contempla 3 aplicaciones distintas: la primera compuesta de una operación \textit{map} sencilla, la siguiente compuesta de una operación \textit{map-reduce} y finalmente una operación real también compuesta de una operación \textit{map-reduce}. En el experimento se varía el número de \textit{workers} para ver cómo escalan las aplicaciones, el tamaño de los datos procesados y el número de iteraciones de los procesos. Además, el experimento registra de forma separada el tiempo de lectura, de ejecución, de escritura y de \textit{overhead} de cada aplicación. La conclusión del experimento es que no hay una diferencia sustancial entre ambos \textit{frameworks}.

\newpage

