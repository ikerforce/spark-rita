\chapter{Revisión de literatura}

\noindent En esta sección se resumen las tres investigaciones que se han realizado previamente para comparar los \textit{frameworks} \textit{Dask} y \textit{Spark}. Los resultados obtenidos en cada investigación no son consistentes con los de las demás debido a la implementación, versiones de la herramienta y casos de uso a los que se somete cada \textit{framework}. Sin embargo, las tres investigaciones hacen la comparación de una forma similar y llegan a distintas conclusiones que pueden aportar valor a este trabajo.

En primer lugar, la investigación \cite{comparative-evolution} hace un análisis de cinco sistemas de \textit{Big Data}. Entre ellos se incluyen los \textit{Resilient Distributed Datasets (RDDs)} de \textit{Spark} y los objetos \textit{futures} y \textit{delayed} de \textit{Dask}. Tanto los \textit{RDDs} como los objetos \textit{futures} y \textit{delayed} son abstracciones de más bajo nivel que los \textit{DataFrames} pero tienen características similares. El experimiento se enfoca en el procesamiento de imágenes y compara el desempeño de las herramientas en dos procesos que se ejecutan con seis diferentes tamaños de datos y en cúmulos de computadoras de tres tamaños distintos. Los resultados obtenidos en el ambiente local sugieren un desempeño similar entre \textit{Dask} y \textit{Spark} para el primero de los procesos y un desempeño superior de \textit{Dask} en el segundo proceso (en general, \textit{Dask} fue un $14\%$ más rápido que \textit{Spark}). No obstante, el estudio advierte que \textit{Dask} presentó problemas de falta de memoria que le impidieron completar uno de los procesos cuando se utilizó el conjunto de datos de mayor tamaño. Por otro lado, con los distintos tamaños de cúmulos, \textit{Dask} tuvo un desempeño ligeramente superior que incrementó junto con el tamaño del cúmulo. Sin embargo, para el cúmulo más pequeño, \textit{Dask} volvió a presentar errores de memoria que le impidieron ejecutar correctamente los procesos. Adicionalmente, la investigación hace un análisis cualitativo para evaluar la facilidad de implementación utilizando cada una de las herramientas y destaca ventajas de \textit{Spark} como el gran tamaño de su comunidad y documentación disponible y la facilidad de implementar funciones de \textit{Python} mediante \textit{User Defined Functions}. Además, menciona desventajas como la dificultad de implementación para desarrolladores no familiarizados con la programación funcional, la falta de \textit{caching} de forma predeterminada que puede resultar en recalcular resultados de forma innecesaria y finalmente advierte que afinar los parámetros para el uso de recursos no es trivial. Por otro lado, para \textit{Dask}, destaca como ventajas su fácil instalación y despliegue, su compatibilidad con bibliotecas externas de \textit{Python} y la similitud de su interfaz con otras herramientas populares. Sin embargo, menciona desventajas como la construcción no trivial de la gráfica de ejecución debido a las múltiples formas de hacerlo, la dificultad de encontrar errores en el código (\textit{debugging}) y la inestabilidad que presenta para ejecutar algunos procesos.

En segundo lugar, la investigación \cite{dask-spark-neuroimaging} hace un comparativo entre \textit{Dask} y \textit{Spark} enfocándose también en procesamiento de imágenes mediante el uso de las abstracciones de más bajo nivel para ambas herramientas (\textit{Futures, Bags} y \textit{Delayed} para \textit{Dask} y \textit{RDDs} para \textit{Spark}). La investigación contempla tres aplicaciones distintas: la primera compuesta de una operación \textit{map} sencilla, la siguiente compuesta de una operación \textit{map-reduce} y finalmente una operación real también compuesta de una operación \textit{map-reduce}. En el experimento se varía el número de \textit{workers} para ver cómo escalan las aplicaciones, el tamaño de los datos procesados y el número de iteraciones de los procesos. Además, el experimento registra de forma separada el tiempo de lectura, de ejecución, de escritura y de \textit{overhead} de cada aplicación. La conclusión del experimento es que no hay una diferencia sustancial entre ambos \textit{frameworks}.

Por último, en \cite{koalas-dask}, un experimento realizado por \textit{Databricks}, se hace una comparación entre \textit{Dask} y \textit{Koalas} (una biblioteca que implementa la API de \textit{Pandas} sobre \textit{Spark}) usando el conjunto de datos \textit{NYC Taxi and Limousine Commission (TLC) Trip Record Data} (157 GB). Para compararlos se usa un ambiente local y uno distribuido con tres \textit{workers}. Este análisis se centra en el uso de operaciones estándar, operaciones estándar junto con filtrado de datos y, por último, operaciones estándar junto con filtrado de datos y \textit{caching}. Para compararlo usan la versión \texttt{2021.03.0} de \textit{Dask} y la \texttt{1.7.0} de \textit{Koalas} implementada sobre \textit{Spark} \texttt{3.0.1}. La conclusión del experimento es que \textit{Koalas} es superior a \textit{Dask} en la mayoría de los escenarios ya que alcanzó un desempeño promedio 4 veces mayor en el ambiente local y 7.9 veces superior en el distribuido, con \textit{Koalas} teniendo especial ventaja en los procesos que involucran cálculos estadísticos y \textit{joins} con filtrado de datos. La investigación concluye que la superioridad de \textit{Koalas} se debe a la capacidad de optimización del plan de ejecución y a estar construido sobre \textit{Spark}.

\newpage

