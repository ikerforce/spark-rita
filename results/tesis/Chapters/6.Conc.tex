\chapter*{Conclusiones}
\addcontentsline{toc}{chapter}{Conclusiones}

% Las conclusiones tampoco cuentan como capítulo

\section{Conclusiones sobre la investigación}

Esta investigación realizó un total de 14,280 ejecuciones de procesos en dos \textit{frameworks} para ejecución de tareas de \textit{Big Data}: \textit{Dask} y \textit{Spark}, en dos ambientes distintos (uno distribuido en la nube y otro local en un solo equipo) y a través de cinco muestras distintas con el objetivo de evaluar bajo qué condiciones uno es superior que el otro y determinar las fortalezas y áreas de oportunidad de cada uno. Los resultados revelaron que \textit{Dask} obtuvo mejores resultados en todos los aspectos cuando las muestras eran inferiores a 11 millones de registros. Es decir, que alcanzó: tiempos de ejecución total más cortos, tiempos de escritura menores, una menor variación en la duración de los procesos, un menor tiempo de inicio de la ejecución, un menor tiempo de cálculo de los resultados y una efectividad del 100\% para la ejecución de las tareas. Por otro lado, para muestras superiores a 11 millones de datos, \textit{Spark} demostró ser superior para la ejecución de tareas que involucran agregaciones con una llave creada durante el proceso y también presentó menores tiempos de escritura a \textit{MySQL} cuando el resultado excedió 436,680 registros y, por último, resultó ser más robusto ya que completó un mayor porcentaje de sus ejecuciones. Por otro lado, \textit{Dask} mostró mejor desempeño en las tareas de agregación como promedios, obtención del máximo y obtención del mínimo cuando las llaves de agregación ya estaban dadas, en la eliminación de valores nulos y una escritura mucho más rápida a archivos \texttt{parquet}. Además, en el proceso iterativo para encontrar la ruta mínima, \textit{Spark} registró tiempos mucho mayores a los de \textit{Dask}. Adicional a lo anterior, \textit{Dask} también registró tiempos de inicio de la ejecución menores y menor variación en la mayoría de los procesos.  En suma, \textit{Dask} obtuvo mejores resultados en la mayoría de los rubros pero no se puede olvidar que la brecha que tenía de ventaja con \textit{Spark} se cerraba conforme aumentaba el tamaño del conjunto procesado, por lo que un análisis con un conjunto de datos mayor podrá aportar valiosa información adicional.

Considerando la adopción y el uso de la herramienta, \textit{Dask} me resultó más sencillo de instalar, empezar a usar e integrar con herramientas de \textit{Python}, además está acompañado de una documentación clara y fácil de consultar, una comunidad pequeña pero activa que ayuda con la resolución de problemas, un portal de usuario fácil de entender y utilizar y una parametrización automática que ayuda a optimizar el uso de los recursos sin la necesidad de conocer a fondo la herramienta. \textit{Spark}, por su parte, es más difícil de adoptar debido que tiene una interfaz distinta a las convencionales pero también cuenta con una gran similitud con procesos de \textit{SQL} que pueden facilitar la migración o adopción de este tipo de procesos. Además, cuenta con un gran repertorio de funciones listas para ser utilizadas que resuelven un gran número de tareas y también considero que es una herramienta más versátil ya que tienen integración con múltiples herramientas de procesamiento y almacenamiento de datos como sistemas de archivos, bases de datos y herramientas en la nube que hacen que la transición a ambientes distribuidos sea más sencilla. Adicionalmente, tiene una gran capacidad para operar con datos ``sucios''. Además de esto, \textit{Spark} se apoya en una comunidad grande y activa que dota a sus usuarios de múltiples recursos para consulta y resolución de problemas. Por último, la parametrización de trabajos es más compleja en \textit{Spark} pero permite un mayor grado de personalización al usuario, lo que da mayor libertad a usuarios familiarizados con la herramienta para configurarla de acuerdo a sus necesidades específicas. Sintetizando, creo que en cuanto al uso, \textit{Dask} es más fácil de adoptar y tiene enormes capacidades pero es una herramienta más nueva que tiene mucho por desarrollar, mientras que \textit{Spark} es más madura, compatible con muchas otras herramientas y ofrece a sus usuarios una gran cantidad de recursos para mejorar el uso de la misma.

La investigación demostró que elementos como la cantidad de datos procesados y la capacidad de escritura jugaron papeles importantes en el cambio del comportamiento de cada \textit{framework}. Sin embargo, también reveló que mediciones y experimentos adicionales podrían ser de gran valor para futuros implementadores. Por ejemplo, creo que medir tareas adicionales de forma independiente como la lectura o el cálculo de operaciones aritméticas podría ser de gran valor para la investigación. También, considero que utilizar métricas adicionales como el tiempo total de ejecución entre el número de registros o la duración total entre el número de computadoras utilizadas, podrían aportar nuevas conclusiones interesantes. Por último, creo que hacer una mayor variación de las configuraciones de los \textit{frameworks} como el número de particiones o el número de ejecutores por nodo puede aportar mucho ya que dará información adicional sobre una mejor parametrización de los trabajos. La investigación de estos aspectos sale del alcance de este trabajo, pero considero que es una buena base para iniciarla, por lo que invito a los lectores a continuarla.

\section{Trabajo futuro}

Aunque los resultados obtenidos dan información importante sobre los \textit{frameworks} y sus capacidades, también crean nuevas preguntas sobre su comportamiento. En particular, creo que sería muy valioso extender el análisis realizado a herramientas como \textit{Pandas} que no están optimizadas para trabajar con volúmenes de datos tan extensos pero que ayudarán a establecer a partir de qué momento y para qué casos de uso específicos es mejor usar los \textit{frameworks} de \textit{Big Data} y cuándo herramientas convencionales son suficientes o incluso mejores para cumplir el propósito. Por otro lado, el análisis realizado evidenció una tendencia de \textit{Spark} para acercarse al desempeño de \textit{Dask} e incluso superarlo cuando el conjunto de datos aumentaba en tamaño, por lo que considero que probar los procesos con conjuntos de datos de mayor tamaño ayudará a hacer una mejor comparación de ambos \textit{frameworks}. Sin embargo, para esto probablemente se requerirá de un conjunto de datos nuevo o de datos sintéticos creados a partir del usado en esta investigación ya que el total de los datos no es mucho mayor que el conjunto utilizado en el análisis anterior. Adicionalmente, el tiempo de escritura demostró ser un factor importante en muchos casos, por lo que creo que ampliar el análisis a escritura a otras fuentes de datos y con configuraciones distintas ayudará a entender mejor los alcances de cada \textit{framework} y a determinar hasta qué punto las capacidades de escritura son un factor decisivo para elegir entre uno y otro. Por otra parte, creo que hacer una separación aún mayor de las operaciones de los \textit{frameworks}, por ejemplo, midiendo el tiempo de lectura de datos de forma separada, ayudará a conocer más sobre las capacidades de cada uno y a entender mejor el tiempo total de ejecución. Y por último, pienso que utilizar un ambiente en la nube con mayores capacidades como servidores con más procesadores o incrementar el número de nodos puede dar información adicional sobre el nivel de escalamiento con el que cuenta cada uno de los \textit{frameworks}.
