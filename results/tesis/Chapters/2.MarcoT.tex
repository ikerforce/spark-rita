\chapter{Marco teórico}

\noindent El objetivo de este análisis es introducir al cómputo en paralelo y distribuido y describir las capacidades principales de los \textit{frameworks}  de \textit{Big Data}: \textit{Spark} y \textit{Dask}.

\newpage


\section{Apache Spark}

Apache Spark es un motor de cómputo unificado con bibliotecas para procesamiento de datos en paralelo en clústeres de computadoras. Soporta múltiples lenguajes de programación como Python, Java, Scala y R. Entre sus aplicaciones más comunes están trabajos de SQL, \textit{streaming} y \textit{machine learning}.\cite{sparkguide}. Debido a que soporta múltiples sistemas de almacenamiento como HDFS, S3, Cassandra y SQL, Spark facilita el cómputo de datos proveniente de diversas fuertes y la unión de las mismas. El desempeño de Spark en múltiples actividades como conteo de palabras y ejecución de consultas de \textit{SQL} es comparable al de herramientas diseñadas para propósitos específicos como \textit{Imapala} y \textit{Storm} \cite{sparkberkeley}, lo que lo convierte en un \textit{framework} multipropósito competitivo.

\subsection{Arquitectura de Spark}

Una aplicación de Spark consiste de un proceso \textit{driver} y un conjunto de procesos llamados \textit{executor}. Ambos tipos de procesos trabajan en conjunto durante la ejecución de la aplicación. El proceso \textit{driver} es la parte central de la aplicación, ya que se encarga de mantener información sobre la aplicación, responder a las instrucciones del usuario y analizar, distribuir y calendarizar el trabajo entre los ejecutores. Este proceso existe en uno solo de los nodos y está en constante comunicación con los demás. \cite{sparkguide}. Los \textit{executors}, por otra parte, tienen el objetivo de realizar el trabajo que el \textit{driver} les asigna. Estos se encargan de ejecutan el trabajo y guardan datos para la aplicación \cite{sparkclusteroverview}.

La abstracción de datos principal en Spark son los \textit{Resilient Distributed Datasets (RDDs)} que son colecciones de objetos efímeras, particionadas en un clúster y que se pueden manipular en paralelo a través de transformaciones. Además, estas transformaciones tienen un \textit{lazy evaluation}, es decir que no realizan la acción inmediatamente, sino que la añaden a un plan eficiente de ejecución. Al llamar una acción, que es una instrucción para calcular un resultado a partir de las transformaciones del plan, \textit{Spark} evalúa la gráfica que fue creada a a partir de las transformaciones y lo ejecuta de forma modular y eficiente \cite{sparkberkeley}.

Otra característica importante de Spark es su capacidad para recuperarse después de fallos. A diferencia de otras herramientas, Spark no almacena resultados intermedios, sino que usa una estrategia llamada linaje en la que cada \textit{RDD} mantiene un registro de las transformaciones que se realizaron para construirlo y las vuelve a ejecutar en caso de que haya alguna falla. Realizar la recuperación de este forma tiene ventajas ya que es ligera en almacenamiento y no requiere operaciones de escritura. Además, la recuperación de información se puede realizar en paralelo en diferentes nodos, lo que acelera el proceso \cite{sparkberkeley}.

Para permitir la ejecución en paralelo, Spark divide los datos en fragmentos llamados \textbf{particiones}, que son una colección de registros que están en una computadora física específica \cite{sparkguide}. Es importante notar que el usuario no interactúa de forma explícita con las particiones, sino que da instrucciones de alto nivel y Spark decide cómo se ejecutarán en el clúster.

\subsection{DataFrames}

Los \textit{DataFrames} de Spark son la API estructurada más popular del \textit{framework} y permiten representar tablas de datos a través de renglones y columnas nombradas. Y pueden extenderse a múltiples computadoras \cite{sparkguide}. Estas estructuras buscan que se pueda interactuar con los datos de la misma forma que en bases de datos analíticas. Los \textit{DataFrames} son \textit{RDDs} que cumplen con un esquema específico \cite{sparkberkeley}. Se pueden manipular mediante \textit{queries} de \textit{SQL} y con funciones preestablecidas como filtrado de datos y agregaciones \cite{sparkberkeley}. Esta estructura es la que más se utilizará durante esta investigación.

\subsection{Mejores prácticas de Apache Spark}

Para optimizar el uso de recursos y reducir los tiempo de ejecución se siguieron las prácticas de \cite{sparkibm}. La siguiente lista corresponde a los puntos más importantes.

\begin{itemize}
	\item Sólo mantener las \textbf{acciones} necesarias. Dado que estas son evaluadas de forma inmediata, pueden afectar al plan de ejecución y provocar planes poco eficientes.
	\item Almacenar los datos en un formato columnar optimizado para lectura y escritura como \texttt{parquet} o \texttt{orc}.
	\item Evitar un gran número de archivos pequeños.
	\item Aumentar el número de particiones para aprovechar el paralelismo.
	\item Buscar entre 2 y 3 \textit{tasks} por ejecutor.
	\item Cambiar el valor del parámetro \textit{shuffle partitions} en caso de tener conjuntos de datos muy grandes. Cuando el conjunto de datos es muy grandes el tamaño de cada partición debe estar entre 100 y 200 MB. Usar la fórmula: \texttt{spark.sql.shuffle.partitions} = quotient (shuffle stage input size/target size)/total cores) * total cores.
	\item Evitar \textit{shuffles}, es decir que datos tengan que ser compartidos entre nodos.
	\item Reduce o filtra los datos lo más pronto posible.
	\item Cuando la misma operación se ejecuta múltiples veces, usa \textit{cache} y elimina los datos en el \textit{cache} cuando ya no sean necesarios.
	\item Cuando se esté haciendo un join con una tabla pequeña, usar \texttt{BroadcastHashJoin}.
	\item Si vas a hacer múltiples \textit{joins}, empieza por el más selectivo para reducir el número de registros.
	\item Evita \textit{cross joins}
	\item Configura el uso de recursos del clúster dependiendo del administrador de recursos y la versión de Spark.
	\item Configura los parámetros: \texttt{spark.driver.memory}, \texttt{executor-memory}, \texttt{num-executors} y \texttt{executor-cores} de acuerdo a los recursos del clúster.
	\item Evita operaciones costosas como \texttt{order by}, seleccionar todas las columnas usando \texttt{\*} en lugar de dar los nombres específicos y no usar \texttt{count} de forma innecesaria.
	\item Asegurarse de que las particiones tengan tamaños similares para que los recursos se utilicen de forma equitativa. En algunos casos, puede ser útil usar \texttt{repartition} para evitar el sesgo hacia alguna partición, pero esto se debe de hacer con cuidado y poca frecuencia ya que la operación es muy costosa.
	\item De ser posible, utiliza las funciones nativas de \textit{Spark} en lugar de crear funciones personalizadas.
	 	
\end{itemize}

\section{Dask}

Dask es una librería de Python para cómputo en paralelo que extiende herramientas populares en el análisis de datos como \textit{NumPy}, \textit{Pandas} y \textit{Python iterators} a tareas que no caben en memoria o a ambientes distribuidos. Además, cuenta con un calendarizador dinámico de tareas y está desarrollado totalmente en \textit{Python}. Se puede utilizar en modo \textit{standalone} o en clústeres con cientos de máquinas. Dask ofrece una interfaz familiar ya que emula a \textit{Numpy} y \textit{Pandas} \cite{daskdocs}. Al usar esta interfaz se genera una gráfica de tareas de forma automática que después es ejecutada en paralelo. Además Dask cuenta con distintas formas de ejecutar las tareas, sin embargo este trabajo se concentra en el modo \textit{Dask Distributed} que fue diseñado para ejecución en clústeres pero funciona en ambientes locales también \cite{daskscheduling}.

\subsection{Arquitectura de \textit{Dask}}

Para la ejecución de tareas, \textit{Dask} usa un calendarizador central, distribuido y dinámico. A través de un proceso llamado \textit{dask-scheduler}, coordina las acciones de múltiples \textit{dask-workers} que se ubican en diferentes máquinas. El calendarizador es asíncrono y orientado a eventos, lo que le permite manejar múltiples trabajos de forma simultánea y gestionar las tareas de los \textit{dask-workers} de forma eficiente y recuperarse de fallos. Todas las tareas generadas por los usuarios se añaden a una Gráfica acícilca dirigida (\textit{DAG} por sus siglas en inglés) que crece cuando se añaden tareas, se actualiza al completarlas y se reduce cuando resultados previos ya no son necesarios \cite{daskdistributed}. Esta forma de asignar las tareas permite una ejecución eficiente de las mismas y mantiene un linaje de las tareas programadas.

Para poder operar con conjuntos de datos más grandes que la memoria disponible, \textit{Dask} divide los datos en segmentos más pequeños llamados particiones. En el caso de los \textit{DataFrames}, que es la estructura que más utilizaremos en esta investigación, las particiones son \textit{Pandas DataFrames}. Estos segmentos corresponden a un conjunto de renglones del \textit{DataFrame} completo.


\subsection{DataFrames}

Un \textit{Dask DataFrame} es ua estructura paralela y grande, compuesta de múltiples \textit{Pandas DataFrames} más pequeños y separados sobre un índice llamados particiones. Los \textit{DataFrames} pueden estar en memoria o en disco en una o múltiples máquinas. Una operación sobre un \textit{Dask DataFrame} ejecuta múltiples operaciones en los \textit{Pandas DataFrames que lo componen} \cite{daskdataframe}. No obstante, es importante notar que los \textit{Dask DataFrames} no implementan todas las capacidades de \textit{Pandas} por lo que puede haber funciones que aún no estén implementadas o operaciones que sean más costosas que en un \textit{Pandas DataFrame} que cabe en memoria.


\subsection{Mejores prácticas en Dask}

En el caso de \textit{Dask}, se siguieron las siguientes mejores prácticas listadas en \cite{daskbestpractices}:
\begin{itemize}
	\item Usar \textit{Pandas} para datos que quepan en memoria.
	\item Reduce el tamaño de un conjunto de datos grande con \textit{Dask} y ya que el conjunto sea suficientemente pequeño continúa el resto de las operaciones con \textit{Pandas}.
	\item Sigue las mejores prácticas de Pandas ya que estas normalmente aplican a los \textit{Dask Dataframes}. Esto incluye evitar usar \texttt{apply} y usar operaciones vectorizadas.
	\item Utiliza el \texttt{index} de \textit{Dask} cuando sea posible. Esto acelerará las operaciones que usen esa columna. A veces utilizar el método \texttt{set\_index} puede acelerar el cómputo pero hay que tener en cuenta que es una operación muy costosa por lo que se debe hacer con poca frecuencia y se debe usar \texttt{persist} posteriormente.
	\item Evita operaciones que requieran \textit{data shuffling} que reubican los datos y son intensivas en comunicación entre los \textit{dask workers}. 
	\item Usa \texttt{persist} de manera inteligente para mantener en memoria los datos que serán utilizados nuevamente y así evitar recalcularlos. Esto es ideal hacerlo después de operaciones como carga de datos, filtrado y operaciones que impliquen un \textit{shuffle} de los datos.
	\item Mantén el número de particiones en un rango adecuado para evitar sobrecarga en la memoria o para aumentar el grado de paralelización. Procura seguir las siguientes guías: Las particiones deben de caber en memoria cómodamente, preferiblemente ser menores a 1 GB. Procura tener pocas particiones. Las particiones deben tener un tamaño aproximado de 100 MB. Después de reducir tus datos, usa \texttt{repartition} para reducir el número de particiones.
	\item Reduce el número de particiones antes de hacer operaciones que impliquen \textit{data shuffling}, ya que estas crean $n \log{n}$ tareas para $n$ particiones, por lo que es más sencillo hacer un \textit{shuffle} de \textit{DataFrames} con 100 particiones o menos que uno con miles de particiones.
	\item Los \textit{joins} en \textit{Dask} son poco costosos en los siguientes casos: Unir dos \textit{Dask DataFrames} por sus columnas índice, Unir un \textit{Dask DataFrame} con un Unir dos \textit{Pandas DataFrame} o unir un \textit{Dask DataFrame} con otro \textit{Dask DataFrame} que esté en una única partición. Evita unir dos \textit{Dask DataFrames} por columnas que no sean el índice ya que esto es muy costoso.
	\item Almacena y carga los datos en formato \textit{Apache Parquet}.
\end{itemize}

\section{Algoritmo de Dijkstra}


El algoritmo de Dijkstra fue diseñado por el computólogo Edsger Dijkstra en 1959 para encontrar el camino más corto a través de una gráfica \cite{dijkstraexplicado}. Este algoritmo es utilizado ampliamente en distintas industrias y entre sus ejemplos más populares son la búsqueda de rutas de Google Maps y para protocolos de \textit{routeo} para encontrar las rutas menor concurridas en internet. Además tiene ventajas como que la ruta es la óptima y que una vez encontrada la ruta al destino especificado, el algoritmo puede detenerse sin la necesidad de visitar el resto de los nodos \cite{dijkstrabellford}. Una de sus desventajas es la gran capacidad de cómputo que requiere, ya que consume mucho CPU y memoria para calcular la ruta óptima en gráficas extensas. Esto lo convierte en un caso de uso ideal para la investigación ya que los \textit{frameworks} buscan satisfacer procesos que requieran grandes cantidades de recursos de cómputo. Además, provee al análisis de un caso de uso más complejo \cite{dijkstrabellford}. Los pasos necesarios para ejecución se especifican en \cite{dijkstrabellford} y son los siguientes:

El algoritmo tiene como argumentos de entrada la gráfica $G$ que se va a recorrer y el nodo origen $v_0$ desde el cual iniciará la ruta al resto de los nodos.

\begin{algorithm}[H]
\caption{Dijkstra}\label{Dijkstra}
\begin{algorithmic}[1]
\Procedure{Dijkstra($G$, $v_{0}$)}{}
\For{\texttt{$v$ in $V(G)$}}
	\State $distancia[v] \gets \infty$
	\State $anterior[v] \gets $ indefinido
	\State añadimos $v$ a $D$, el conjunto de vértices de la gráfica.
\EndFor
\State $distancia[v_{0}] \gets 0$

\While{$D$ no esté vacío}:
	\State Seleccionamos un $u$ tal que $distancia[u]$ tiene el valor mínimo en $D$
	\State Elimino $u$ de $D$
	\For {$v$ en $\{ v \ | \ (u, v) \in E(G)\}$}
		\State $temporal \gets distancia[u] + peso(u, v)$
		\If {$temporal < distancia[v]$}
			\State $distancia[v] \gets alt$
			\State $previo[v] \gets u$		
		\EndIf
	\EndFor
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

Para la investigación se implementó un algoritmo con una lógica similar a la de Dijkstra pero con restricciones adicionales. El objetivo del algoritmo es encontrar la ruta más corta en duración total del trayecto entre cualesquiera dos aeropuertos del conjunto de datos.

La ruta óptima será aquella con menor diferencia de tiempo entre el horario de salida del origen y el horario de llegada al destino final. Para penalizar el número de escalas y hacer las rutas calculadas por el algoritmo más factibles, se considera un tiempo mínimo de 2 horas entre la llegada de un vuelo y la salida del siguiente para permitir un tiempo adecuado de transbordo. Además, la gráfica es dinámica ya que al seleccionar un vuelo que conecta dos destinos, se eliminan aquellos que tengan un horario de salida menor al horario de llegada anterior más el tiempo de escala (2 horas). Adicionalmente, en caso de que exista un vuelo directo, este se seleccionará automáticamente como el óptimo y en caso de que haya múltiples horarios se elegirá el horario factible más cercano al horario especificado por el usuario. Por otro lado, el algoritmo deja de explorar la gráfica una vez que se alcance el destino deseado, ya que el algoritmo de Dijkstra asegura que la ruta alcanzada es la óptima aún sin haber visitado todos los nodos.

Las entradas del algoritmo son $M$, una multigráfica en la que los nodos son aeropuertos y cuyas aristas corresponden a los vuelos que las conectan. El peso de las aristas representa la duración de cada uno de los vuelos. Es importante notar que dos nodos pueden estar conectados por múltiples aristas debido a que más de un vuelo y horario conecta los aeropuertos. Además, para reducir el espacio de búsqueda se requiere de un \texttt{horario} deseado de salida. El itinerario que resultará de la ejecución del algoritmo tendrá horario de salida del origen dentro de un intervalo de 7 días a partir de la fecha especificada por la variable \texttt{horario}.

Para su ejecución, el algoritmo requiere de las siguientes entradas:

\begin{itemize}
	\item $M$ Multigráfica formada de los aeropuertos como nodos y los vuelos como aristas.
	\item $origen$ Aeropuerto de origen. Este es el nodo a partir del cuál iniciará el cálculo de la ruta.
	\item $destio$ Aeropuerto de destino final. Al llegar a este nodo se detendrá la ejecución.
	\item $horario$ Horario aproximado de salida. El itinerario resultante tendrá horario de salida en el intervalo $[horario,\  horario$ $+$ 7 días$]$
\end{itemize}

\begin{algorithm}[H]
\caption{Dijkstra modificado}\label{dijkstra_modificado}
\begin{algorithmic}[1]
\Procedure{Dijkstra modificado($M$, $origen$, $destino$, $horario$)}{}
\State Definimos el conjunto de aristas factibles $E_{f}(M)$ como: $E_{f}(M) = \{(u,v)\ |\ salida[(u, v)] \in [horario,\  horario$ $+$ 7 días$]\}$
\If {$(origen, destino) \in E_{f}(M)$}
	\State $optimo = \{{(origen, destino)}_{0}\ |\ salida[(origen, destino)] = min(salida[(origen, destino)])\}$
\Else
	\For{\texttt{$v$ in $V(G)$}}
		\State $distancia[v] \gets \infty$
		\State $anterior[v] \gets $ indefinido
		\State añadimos $v$ a $D$
	\EndFor
	\State $distancia[v_{0}] \gets 0$
	
	\While{$D$ no esté vacío $|\ v \neq dest$}:
		\State Seleccionamos un $u$ tal que $distancia[u]$ tiene el valor mínimo en $D$
		\State Elimino $u$ de $D$
		\For {$v$ en $\{ v \ | \ (u, v) \in E_{f}(M)\}$}
			\State $temporal \gets distancia[u] + peso(u, v)$
			\If {$temporal < distancia[v]$}
				\State $distancia[v] \gets alt$
				\State $previo[v] \gets u$
				\State $E_{f}(M) \gets \{(u, v) \in E_{f}(M)\ |\ salida[(u,v)] > temporal + 2$ horas$\}$
			\EndIf
		\EndFor
	\EndWhile
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}
