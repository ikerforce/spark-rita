\chapter{Marco teórico}

\noindent El objetivo de este análisis es introducir al cómputo en paralelo y distribuido y describir las capacidades principales de los \textit{frameworks}  de \textit{Big Data}: \textit{Spark} y \textit{Dask}.

\newpage


\section{Apache Spark}

\textit{Apache Spark} es un motor de cómputo unificado con bibliotecas para procesamiento de datos en paralelo en clústeres de computadoras. Soporta múltiples lenguajes de programación como \textit{Python}, \textit{Java}, \textit{Scala} y \textit{R}. Entre sus aplicaciones más comunes están trabajos de SQL, \textit{streaming} y \textit{machine learning}\cite{sparkguide}. Debido a que soporta múltiples sistemas de almacenamiento como \textit{HDFS}, \textit{S3}, \textit{Cassandra} y \textit{SQL}, \textit{Spark} facilita el cómputo de datos proveniente de diversas fuertes y la unión de las mismas. El desempeño de \textit{Spark} en múltiples actividades como conteo de palabras y ejecución de consultas de \textit{SQL} es comparable al de herramientas diseñadas para propósitos específicos como \textit{Imapala} y \textit{Storm} \cite{sparkberkeley}, lo que lo convierte en un \textit{framework} multipropósito competitivo.

\subsection{Arquitectura de Spark}

Uno de los elementos centrales de \textit{Spark} es su \textit{Lazy Evaluation}, es decir, que espera hasta el último momento para ejecutar las operaciones indicadas por el usuario. Cada instrucción se añade a un plan de ejecución que se aplica a los datos iniciales que es ejecutado al llamar una acción. Crear este plan y esperar hasta el último momento para ejecutarlo, le permite a \textit{Spark} analizarlo y optimizarla para hacer su ejecución lo más eficiente posible. Un ejemplo concreto es un filtro que se realiza al final del plan de ejecución, cuando este se puede ejecutar antes sin cambiar el proceso general, \textit{Spark} lo pondrá antes en el plan de forma automática para reducir los datos que tiene que procesar y así reducir el tiempo de ejecución.

Una aplicación de \textit{Spark} consiste de un proceso \textit{driver} y un conjunto de procesos llamados \textit{executor}. Ambos tipos de procesos trabajan en conjunto durante la ejecución de la aplicación. El proceso \textit{driver} es la parte central de la aplicación, ya que se encarga de mantener información sobre la aplicación, responder a las instrucciones del usuario y analizar, distribuir y calendarizar el trabajo entre los ejecutores. Este proceso existe en uno solo de los nodos y está en constante comunicación con los demás. \cite{sparkguide}. Los \textit{executors}, por otra parte, se encargan de realizar el trabajo que el \textit{driver} les asigna y de almacenar los datos utilizados durante la ejecución de la aplicación \cite{sparkclusteroverview}.

La abstracción de datos principal en \textit{Spark} son los \textit{Resilient Distributed Datasets (RDDs)} que son colecciones de objetos efímeras, particionadas en un clúster y que se pueden manipular en paralelo a través de \textit{transformaciones}. Además, estas transformaciones tienen una evaluación perezosa (\textit{lazy evaluation}), es decir que no realizan la acción inmediatamente, sino que la añaden a un plan eficiente de ejecución. Al llamar una \textit{acción}, que es una instrucción para calcular un resultado a partir de las transformaciones del plan, \textit{Spark} evalúa la gráfica que fue creada a partir de las transformaciones y lo ejecuta de forma modular y eficiente \cite{sparkberkeley}.

Otra característica importante de \textit{Spark} es su capacidad para recuperarse después de fallos. A diferencia de otras herramientas, \textit{Spark} no almacena resultados intermedios de manera predeterminada, sino que usa una estrategia llamada linaje en la que cada \textit{RDD} mantiene un registro de las transformaciones que se realizaron para construirlo y las vuelve a ejecutar en caso de que haya alguna falla. Realizar la recuperación de este forma tiene ventajas ya que es ligera en almacenamiento y no requiere operaciones de escritura. Además, la recuperación de información se puede realizar en paralelo en diferentes nodos, lo que acelera el proceso \cite{sparkberkeley}.

Para permitir la ejecución en paralelo, Spark divide los datos en fragmentos llamados \textit{particiones}, que son una colección de registros que están en una computadora física específica \cite{sparkguide}. Es importante notar que el usuario no interactúa de forma explícita con las particiones, sino que da instrucciones de alto nivel y Spark decide cómo se ejecutarán en el clúster.

\subsection{DataFrames}

Los \textit{DataFrames} de Spark son la API estructurada más popular del \textit{framework} y permiten representar tablas de datos a través de renglones y columnas nombradas y pueden extenderse a múltiples computadoras \cite{sparkguide}. Estas estructuras buscan que se pueda interactuar con los datos de la misma forma que en bases de datos analíticas. Los \textit{DataFrames} son \textit{RDDs} que cumplen con un esquema específico \cite{sparkberkeley}. Se pueden manipular mediante \textit{queries} de \textit{SQL} y con funciones preestablecidas como filtrado de datos y agregaciones \cite{sparkberkeley}. Esta estructura es la que más se utilizará durante esta investigación.

\subsection{Mejores prácticas de Apache Spark}

Para optimizar el uso de recursos y reducir los tiempo de ejecución se siguieron las prácticas de \cite{sparkibm}. La siguiente lista corresponde a los puntos más importantes.

\begin{itemize}
	\item Mantener únicamente las \textit{acciones} necesarias. Dado que estas son evaluadas de forma inmediata, pueden afectar al plan de ejecución y provocar planes poco eficientes.
	\item Almacenar los datos en un formato columnar (ver \ref{formatocolumnar}) optimizado para lectura y escritura como \texttt{parquet} o \texttt{orc}.
	\item Evitar un gran número de archivos pequeños.
	\item Aumentar el número de particiones para aprovechar el paralelismo.
	\item Buscar entre 2 y 3 \textit{tasks} por ejecutor.
	\item Cambiar el valor del parámetro \texttt{shuffle partitions} en caso de tener conjuntos de datos muy grandes. Cuando el conjunto de datos es muy grande, el tamaño de cada partición debe estar entre 100 y 200 MB. 
	\item Evitar \textit{shuffles}, es decir que los datos tengan que ser transmitidos entre nodos.
	\item Definir un valor adecuado para el parámetro \texttt{shuffle partitions} usando la fórmula siguiente: \texttt{spark.sql.shuffle.partitions} = quotient (shuffle stage input size/target size)/total cores) * total cores.
	\item Reducir o filtrar los datos lo más pronto posible.
	\item Usar \texttt{cache} cuando la misma operación se ejecuta múltiples veces y eliminar los datos en el \texttt{cache} cuando ya no sean necesarios.
	\item Usar \texttt{BroadcastHashJoin} cuando se esté haciendo un \textit{join} con una tabla pequeña.
	\item Empezar haciendo el \textit{join} más selectivo para reducir el número de registros utilizados.
	\item Evitar el uso de \textit{cross joins} (el producto cartesiano de dos tablas, relaciona cada registro de una tabla con todos los de la otra por lo que aumenta significativamente el número de registros).
	\item Configurar el uso de recursos del clúster dependiendo del administrador de recursos y la versión de Spark.
	\item Configurar los parámetros: \texttt{spark.driver.memory}, \texttt{executor-memory}, \texttt{num-executors} y \texttt{executor-cores} de acuerdo a los recursos del clúster. Esto se aborda más a detalle en la siguiente sección.
	\item Evitar el uso de operaciones costosas como \texttt{order by}. 
	\item Seleccionar las columnas usando sus nombres en lugar de seleccionarlas todas con \texttt{*} para evitar cargar columnas que no serán utilizadas.
	\item Usar \texttt{count} sólo cuando sea necesario.
	\item Asegurar que las particiones tengan tamaños similares para que los recursos se utilicen de forma equitativa. En algunos casos, puede ser útil usar \texttt{repartition} para evitar el sesgo hacia alguna partición, sin embargo, esto se debe de hacer con cuidado y poca frecuencia ya que la operación es muy costosa.
	\item Utilizar las funciones nativas de \textit{Spark} en lugar de crear funciones personalizadas cuando sea posible.
\end{itemize}

\subsection{\textit{Hardware} recomendado}

Aunque \textit{PySpark} está diseñado para acoplarse a múltiples configuraciones de \textit{Hardware}, la documentación oficial (\cite{sparkhardware}) propone los siguientes lineamientos para mejorar su desempeño:
\begin{itemize}
	\item Mantener el sistema de almacenamiento de datos lo más cercano posible a donde se hará la ejecución de Spark. Idealmente, el alamacenamiento será en los mismos nodos que la ejecución, pero si esto no es posible, es recomendable que estén en la misma red local.
	\item Tener de 4 a 8 discos por nodo para los casos en los que \textit{PySpark} tenga que almacenar datos temporalmente en disco.
	\item Asignar mínimo 8GB de memoria por máquina y usar a lo más 75\% de la memoria para \textit{PySpark}, dejando el 25\% restante para el sistema operativo y otras tareas de administración del nodo.
	\item Usar al menos entre 8 y 16 cores por nodo. 
\end{itemize}

Después de cumplir las condiciones anteriores en el \textit{Hardware}, hay que seguir las indicaciones de la siguiente sección para optimizar el uso de los recursos.


\subsection{Parametrización de trabajos de \textit{PySpark} en el clúster}

Es importante utilizar los recursos del clúster de forma inteligente para aprovechar al máximo los recursos disponibles. En \cite{sparkconfuds}, se recomienda configurar los parámetros de una aplicación de \textit{Spark} de la siguiente forma:

\begin{itemize}
	\item \texttt{--driver-memory} determina la memoria que se le asignará al \textit{driver} y su valor predeterminado es 1G. Se recomienda aumentarlo cuando se requiera transmitir resultados grandes al \textit{driver} mediante acciones como \texttt{take(n)} o \texttt{collect()}.
	\item \texttt{--driver-cores} determina el número de \textit{cores} que se le asignarán al \textit{driver}. El valor predeterminado es 1, pero se recomienda asignar de 2 a 4 \textit{cores} para clústeres más grandes y aplicaciones complejas. 
	\item \texttt{--num-executors} especifica el número de ejecutores que se crearán para ejecutar las tareas de la aplicación. El número de ejecutores depende de la cantidad de \textit{cores} disponibles en el clúster. Se aconseja dejar, en cada nodo 1 o 2 cores disponibles para tareas independientes del trabajo de \textit{Spark} y asignar entre 2 y 5 \textit{cores} a cada ejecutor dependiendo de las tareas que procesará y el nivel de paralelismo que se busca alcanzar. De acuerdo a \cite{sparkconfcloudera}, mantenerse en este rango evita replicar muchas veces información (lo cual es necesario con ejecutores pequeños) mientras evita la sobrecarga de escritura del \textit{File System}.
	\item \texttt{--executor-memory} asigna memoria a cada \textit{ejecutor}. El valor predeterminado es 1G pero se debe incrementar de acuerdo a la tarea y la cantidad de memoria disponible para cada ejecutor. \cite{sparkconfcloudera} recomienda mantener este valor por debajo de 64GB para evitar que demasiada basura se mantenga en memoria.
	\item \texttt{--executor-cores} determina el número de cores que se asigna a cada ejecutor y va muy de la mano con el parámetro \texttt{--num-executors} por lo que se deben de calcular de manera conjunta. De acuerdo a \cite{sparkconfcloudera}, el número de cores que se le asigna a cada ejecutor determina el número de tareas simultáneas que puede realizar.
\end{itemize}

\section{Dask}

\textit{Dask} es una librería de Python para cómputo en paralelo que extiende herramientas populares en el análisis de datos como \textit{NumPy}, \textit{Pandas} y \textit{Python iterators} a tareas que no caben en memoria o a ambientes distribuidos. Además, cuenta con un calendarizador dinámico de tareas y está desarrollado totalmente en \textit{Python}. Se puede utilizar en modo \textit{standalone} o en clústeres con cientos de máquinas. Dask ofrece una interfaz familiar ya que emula a \textit{Numpy} y \textit{Pandas} \cite{daskdocs}. Al usar esta interfaz se genera una gráfica de tareas de forma automática que después es ejecutada en paralelo. Además Dask cuenta con distintas formas de ejecutar las tareas, sin embargo este trabajo se concentra en el modo \textit{Dask Distributed} que fue diseñado para ejecución en clústeres y que funciona en ambientes locales también \cite{daskscheduling}.

\subsection{Arquitectura de \textit{Dask}}

Para la ejecución de tareas, \textit{Dask} usa un calendarizador central, distribuido y dinámico. A través de un proceso llamado \textit{dask scheduler}, coordina las acciones de múltiples \textit{dask workers} que se ubican en diferentes máquinas. El calendarizador es asíncrono y orientado a eventos, lo que le permite manejar múltiples trabajos de forma simultánea y gestionar las tareas de los \textit{dask workers} de forma eficiente y recuperarse de fallos. Todas las tareas generadas por los usuarios se añaden a una gráfica acícilca dirigida (\textit{DAG} por sus siglas en inglés) que crece cuando se añaden tareas, se actualiza al completarlas y se reduce cuando resultados previos ya no son necesarios \cite{daskdistributed}. Esta forma de asignar las tareas permite una ejecución eficiente de las mismas y mantiene un linaje de las tareas programadas.

Para poder operar con conjuntos de datos más grandes que la memoria disponible, \textit{Dask} divide los datos en segmentos más pequeños llamados particiones. En el caso de los \textit{DataFrames}, que es la estructura que más utilizaremos en esta investigación, las particiones son \textit{Pandas DataFrames}. Estos segmentos corresponden a un conjunto de renglones del \textit{DataFrame} completo.


\subsection{DataFrames}

Un \textit{Dask DataFrame} es ua estructura paralela y extensa, compuesta de múltiples \textit{Pandas DataFrames} más pequeños llamados particiones y que están separados sobre un índice. Los \textit{DataFrames} pueden estar en memoria o en disco en una o múltiples máquinas. Una operación sobre un \textit{Dask DataFrame} ejecuta múltiples operaciones en los \textit{Pandas DataFrames} que lo componen \cite{daskdataframe}, no obstante, es importante notar que los \textit{Dask DataFrames} no implementan todas las capacidades de \textit{Pandas} por lo que puede haber funciones que aún no estén implementadas o operaciones que sean más costosas que en un \textit{Pandas DataFrame} que cabe en memoria.


\subsection{Mejores prácticas en Dask}

En el caso de \textit{Dask}, se siguieron las siguientes mejores prácticas listadas en \cite{daskbestpractices}:
\begin{itemize}
	\item Usar \textit{Pandas} para datos que quepan en memoria.
	\item Reducir el tamaño de un conjunto de datos grande con \textit{Dask} y ya que el conjunto sea suficientemente pequeño continúa el resto de las operaciones con \textit{Pandas}.
	\item Seguir las mejores prácticas de Pandas ya que estas normalmente aplican a los \textit{Dask Dataframes}. Esto incluye usar operaciones vectorizadas y evitar el uso de \texttt{apply}.
	\item Evitar operaciones que requieran \textit{data shuffling} que intercambian los datos y son intensivas en comunicación entre los \textit{dask workers}. 
	\item Usar \texttt{persist} de manera inteligente para mantener en memoria los datos que serán utilizados nuevamente y así evitar recalcularlos. Es preferible hacer esto después de operaciones como carga de datos, filtrado y operaciones que impliquen un \textit{shuffle} de los datos.
	\item Utilizar el \texttt{index} de \textit{Dask} cuando sea posible. Esto acelerará las operaciones que usen esa columna. A veces utilizar el método \texttt{set\_index} puede acelerar el cómputo pero hay que tener en cuenta que es una operación muy costosa por lo que se debe hacer con poca frecuencia y se debe usar \texttt{persist} posteriormente.
	\item Mantener el número de particiones en un rango adecuado para evitar la sobrecarga de la memoria o para aumentar el grado de paralelización. Procurar seguir las siguientes guías: Las particiones deben de caber en memoria cómodamente, preferiblemente ser menores a 1 GB y deben existir pocas particiones, además estas deben tener un tamaño aproximado de 100 MB. 
	\item Usar \texttt{repartition} para reducir el número de particiones después de una reducción significativa de los datos.
	\item Reducir el número de particiones antes de hacer operaciones que impliquen \textit{data shuffling}, ya que estas crean $n \log{n}$ tareas para $n$ particiones, por lo que es más sencillo hacer un \textit{shuffle} de \textit{DataFrames} con 100 particiones o menos que uno con miles de particiones.
	\item Procurar mantenerse dentro de los siguientes casos al hacer \textit{joins}: Unir dos \textit{Dask DataFrames} por sus columnas índice, Unir un \textit{Dask DataFrame} con un \textit{Pandas DataFrame}, unir dos \textit{Pandas DataFrame} y unir un \textit{Dask DataFrame} con otro \textit{Dask DataFrame} que esté en una única partición. 
	\item Evitar unir dos \textit{Dask DataFrames} por columnas que no sean el índice.
	\item Almacenar y cargar los datos en formato \textit{Apache Parquet}.
\end{itemize}

\section{Algoritmo de Dijkstra}


El algoritmo de Dijkstra fue diseñado por el computólogo Edsger Dijkstra en 1959 para encontrar el camino más corto a través de una gráfica \cite{dijkstraexplicado}. Este algoritmo es utilizado ampliamente en distintas industrias y entre sus ejemplos más populares son la búsqueda de rutas de Google Maps y para protocolos de ruteo para encontrar las rutas menor concurridas en internet. Además tiene ventajas como que encuentra la ruta óptima y que una vez encontrada la ruta al destino especificado, el algoritmo puede detenerse sin la necesidad de visitar el resto de los nodos \cite{dijkstrabellford}. Una de sus desventajas es la gran capacidad de cómputo que requiere, ya que consume mucho CPU y memoria para calcular la ruta óptima en gráficas extensas. Esto lo convierte en un caso de uso ideal para la investigación ya que los \textit{frameworks} buscan satisfacer procesos que requieran grandes cantidades de recursos de cómputo. Además, analizar este escenario provee a la investigación de un caso de uso más complejo \cite{dijkstrabellford}. Los pasos necesarios para ejecución se especifican en \cite{dijkstrabellford} y son los siguientes:

El algoritmo tiene los siguientes argumentos de entrada:
\begin{itemize}
	\item $G$ Gráfica que se va a recorrer.
	\item $v_{0}$ Vértice de origen a partir del cual se calculará la ruta óptima.
\end{itemize}

\begin{algorithm}[H]
\caption{Dijkstra}\label{Dijkstra}
\begin{algorithmic}[1]
\Procedure{Dijkstra($G$, $v_{0}$)}{}
\For{\texttt{$v$ in $V(G)$}}
	\State $distancia[v] \gets \infty$
	\State $anterior[v] \gets $ indefinido
	\State añadimos $v$ a $D$, el conjunto de vértices de la gráfica.
\EndFor
\State $distancia[v_{0}] \gets 0$

\While{$D$ no esté vacío}:
	\State Seleccionamos un $u$ tal que $distancia[u]$ tiene el valor mínimo en $D$
	\State Elimino $u$ de $D$
	\For {$v$ en $\{ v \ | \ (u, v) \in E(G)\}$}
		\State $temporal \gets distancia[u] + peso(u, v)$
		\If {$temporal < distancia[v]$}
			\State $distancia[v] \gets alt$
			\State $previo[v] \gets u$		
		\EndIf
	\EndFor
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}

Para la investigación se implementó un algoritmo con una lógica similar a la de Dijkstra pero con restricciones adicionales. El objetivo del algoritmo es encontrar la ruta más corta en duración total del trayecto entre cualesquiera dos aeropuertos del conjunto de datos.

La ruta óptima será aquella con menor diferencia de tiempo entre el horario de salida del origen y el horario de llegada al destino final. Para penalizar el número de escalas y hacer las rutas calculadas por el algoritmo más factibles, se considera un tiempo mínimo de 2 horas entre la llegada de un vuelo y la salida del siguiente para permitir un tiempo adecuado de transbordo. Además, la gráfica es dinámica ya que al seleccionar un vuelo que conecta dos destinos, se eliminan aquellos que tengan un horario de salida menor al horario de llegada anterior más el tiempo de escala (2 horas). Adicionalmente, en caso de que exista un vuelo directo, este se seleccionará automáticamente como el óptimo y en caso de que haya múltiples horarios se elegirá el horario factible más cercano al horario especificado por el usuario. Por otro lado, el algoritmo deja de explorar la gráfica una vez que se alcance el destino deseado, ya que el algoritmo de Dijkstra asegura que la ruta alcanzada es la óptima aún sin haber visitado todos los nodos.

Las entradas del algoritmo son $M$, una multigráfica en la que los nodos son aeropuertos y cuyas aristas corresponden a los vuelos que las conectan. El peso de las aristas representa la duración de cada uno de los vuelos. Es importante notar que dos nodos pueden estar conectados por múltiples aristas debido a que más de un vuelo y horario conecta los aeropuertos. Además, para reducir el espacio de búsqueda se requiere de un \texttt{horario} deseado de salida. El itinerario que resultará de la ejecución del algoritmo tendrá horario de salida del origen dentro de un intervalo de 7 días a partir de la fecha especificada por la variable \texttt{horario}.

Para su ejecución, el algoritmo requiere de las siguientes entradas:

\begin{itemize}
	\item $M$ Multigráfica formada de los aeropuertos como nodos y los vuelos como aristas.
	\item $origen$ Aeropuerto de origen. Este es el nodo a partir del cuál iniciará el cálculo de la ruta.
	\item $destino$ Aeropuerto de destino final. Al llegar a este nodo se detendrá la ejecución.
	\item $horario$ Horario aproximado de salida. El itinerario resultante tendrá horario de salida en el intervalo $[horario,\  horario$ $+$ 7 días$]$
\end{itemize}

\begin{algorithm}[H]
\caption{Dijkstra modificado}\label{dijkstra_modificado}
\begin{algorithmic}[1]
\Procedure{Dijkstra modificado($M$, $origen$, $destino$, $horario$)}{}
\State Definimos el conjunto de aristas factibles $E_{f}(M)$ como: $E_{f}(M) = \{(u,v)\ |\ salida[(u, v)] \in [horario,\  horario$ $+$ 7 días$]\}$
\If {$(origen, destino) \in E_{f}(M)$}
	\State $optimo = \{{(origen, destino)}_{0}\ |\ salida[(origen, destino)] = min(salida[(origen, destino)])\}$
\Else
	\For{\texttt{$v$ in $V(G)$}}
		\State $distancia[v] \gets \infty$
		\State $anterior[v] \gets $ indefinido
		\State añadimos $v$ a $D$
	\EndFor
	\State $distancia[v_{0}] \gets 0$
	
	\While{$D$ no esté vacío $|\ v \neq dest$}:
		\State Seleccionamos un $u$ tal que $distancia[u]$ tiene el valor mínimo en $D$
		\State Elimino $u$ de $D$
		\For {$v$ en $\{ v \ | \ (u, v) \in E_{f}(M)\}$}
			\State $temporal \gets distancia[u] + peso(u, v)$
			\If {$temporal < distancia[v]$}
				\State $distancia[v] \gets alt$
				\State $previo[v] \gets u$
				\State $E_{f}(M) \gets \{(u, v) \in E_{f}(M)\ |\ salida[(u,v)] > temporal + 2$ horas$\}$
			\EndIf
		\EndFor
	\EndWhile
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}
