\chapter{Mi experiencia de implementación}

\noindent Este capítulo tiene como objetivo hacer un análisis cualitativo de la experiencia de implementación utilizando ambos \textit{frameworks}. Se busca comparar la facilidad de uso de cada uno desde la instalación hasta la configuración de trabajos y despliegue en un ambiente distribuido. Contenidas en este capítulo estarán las dificultades que experimenté durante la implementación de los procesos con cada herramienta así como las ventajas que identifiqué con cada uno de ellos.

\section{Mi perfil}

Antes de contrastar ambos \textit{frameworks} es importante describir brevemente mi perfil y el tiempo de experiencia que he tenido con ambas herramientas para intentar explicar mejor por qué favorezco una herramienta sobre la otra en diferentes aspectos. En primer lugar, tengo más de dos años de experiencia en el uso de \textit{Spark}, tanto profesionalmente como personalmente, y una certificación en su uso. Por otro lado, empecé a usar \textit{Dask} hace un poco más de un año con este proyecto como única experiencia. Previamente fui un usuario frecuente de \textit{Pandas}, biblioteca con la que tengo casi cuatro años de experiencia. El lenguaje de programación que más utilizo es \textit{Python} y también tengo más de dos años de experiencia con diversos sistemas de bases de datos tipo \textit{SQL}.

\section{Instalación}

El primer paso en el uso de cualquier herramienta es la instalación de la misma, y en esta sección abordaré las fortalezas y debilidades que encontré en cada \textit{framework} al hacer la instalación local.

\subsection{Instalación de \textit{Spark}}

La instalación de \textit{Spark}, tiene la primera desventaja de que puede tener prerrequisitos adicionales como \textit{Java} y \textit{Scala} que no necesariamente tienen una instalación fácil. Una vez satisfechos los requerimientos, la instalación se puede hacer descargando un archivo comprimido, proceso que puede no ser tan intuitivo sobre todo en sistemas operativos como \textit{MacOS} y \textit{Windows}, pero que creo que es sencillo para usuarios de \textit{Linux}. Después de descomprimir el archivo, \textit{Spark} está prácticamente listo para ser utilizado y además no requiere muchos recursos adicionales para la ejecución de los procesos de esta implementación, la única excepción fue un \texttt{jar} para \textit{MySQL}, pero en general creo que es más autocontenido que \textit{Dask}. Por último, la integración con \texttt{jupyter} puede resultar muy complicada, lo cuál es una gran desventaja ya que esta es una herramienta útil para el desarrollo de aplicaciones.


\subsection{Instalación de \textit{Dask}}

La instalación de \textit{Dask} tiene la ventaja de poderse hacer mediante \texttt{conda} o \texttt{pip}, lo cuál facilita la administración y puede ser más sencillo para usuarios de \textit{Python} por su similitud con la instalación de otras bibliotecas. Otra ventaja es la facilidad de usar \textit{Dask} junto con \texttt{jupyter} y las capacidades adicionales que tienen al usarse juntas, por ejemplo, la visualización del plan de ejecución o de avance de procesos. Esta integración facilita el uso de la herramienta a usuarios familiarizados con esta interfaz. Por otro lado, uno de los problemas que identifique con \textit{Dask} es que requiere de paquetes adicionales para realizar algunas operaciones comunes, ejemplos de esto son \texttt{pymysql}, para la lectura y escritura de bases de datos, y \texttt{pyarrow}, para leer y escribir a archivos \texttt{parquet}. Esto es una desventaja debido a que aunque la instalación de los paquetes adicionales de \textit{Dask} es bastante sencilla (ya que también se pueden realizar con \texttt{conda} y \texttt{pip}), el hecho de que requiera paquetes diferentes puede resultar en problemas entre versiones y dependencias de los paquetes, lo cual sucedió múltiples veces durante esta implementación.

\subsection{Conclusiones sobre el proceso de instalación}

En suma, creo que la instalación de \textit{Dask} es mucho más amigable con usuarios nuevos aunque puede incurrir en errores de versiones debido a bibliotecas adicionales. Sin embargo, considero también que, para usuarios más experimentados, la instalación de \textit{Spark} no tiene gran complejidad y es menos propensa a errores. Además, \textit{Dask} parece más compatible con herramientas con los que los usuarios de \textit{Python} ya están familiarizados, por lo que puede resultarles mucho más sencillo empezar a trabajar con esta herramienta. 

\section{Uso}

Una vez terminada la instalación, empieza el uso de las herramientas. Creo que este es el punto en el que muchos de los nuevos usuarios nuevos deciden si esta herramienta es la adecuada para satisfacer la necesidad que tienen. A continuación mencionaré las que consideré como las más grandes ventajas y desventajas de cada \textit{framework} al empezar a utilizarlos.

\subsection{Uso de \textit{Spark}}

Al principio, \textit{Spark} tuvo un avance lento debido a que la API \textit{PySpark} es distinta a herramientas que conocía antes por aspectos como: la distinta sintaxis, la forma de desplegar errores y sobre todo, la evaluación perezosa. Sin embargo, después de algo de experiencia, la herramienta se empieza a hacer más intuitiva, y el hecho de que se puede interactuar con los \textit{DataFrames}, tanto con la sintaxis de \textit{Spark} como con consultas de \textit{SQL}, permite que la transición sea más sencilla para usuarios que cuentan con experiencia con la última. Adicional a esto, al inicio no es tan fácil distinguir entre las operaciones que son simplemente una transformación de los datos y las acciones que detonan la materialización del resultado y por lo tanto la ejecución del plan de ejecución, lo que puede confundir a un usuario no acostumbrado a la programación funcional. 
Una ventaja es que el conjunto de funciones definidas en \textit{Spark} es muy amplio y permite realizar operaciones complicadas de manera eficiente, con pocos renglones de código y evita la necesidad de que el usuario escriba sus propias funciones. No obstante, cuando esto es necesario, las \texttt{udf} (funciones definidas por el usuario) ayudan a que funciones más personalizadas se puedan escribir en \textit{Python} y ejecutar de forma distribuida fácilmente. Además, durante la implementación de los procesos noté que \textit{Spark} ejecutaba más rápidamente operaciones como conversión de datos o manipulaciones a \texttt{strings}, lo que resultaba en lectura más rápida y manipulación más sencilla de columnas con registros que no correspondían al formato del resto.
\textit{Spark} se conecta de forma nativa a múltiples sistemas de archivos como \textit{Amazon S3}, bases de datos \textit{SQL}, \textit{HDFS} y \textit{Azure Blob Storage} y también a distintos tipos de archivos como \texttt{parquet} y \texttt{avro}, aunque en algunos casos puede ser necesario un \texttt{jar} adicional.

\subsection{Uso de \textit{Dask}}

En el caso de \textit{Dask}, como la interfaz es tan parecida a la de \textit{Pandas} y a que extiende muchas de sus capacidades, la transición es más sencilla para usuarios frecuentes de \textit{Pandas} y en algunos casos un código se puede migrar a \textit{Dask} con mínimas modificaciones. También su similitud con \textit{Pandas} y su gran integración permite intercambiar entre ellos de forma sencilla cuando los datos aumentan o se reducen y así usar la herramienta que mejor se adecúe al caso de uso (el proceso de pasar de \textit{Dask} a \textit{Pandas} fue más sencillo y rápido que cuando se realizaba este proceso con \textit{Spark}). Adicionalmente, \textit{Dask} requiere el uso explícito de la operación \texttt{compute} para materializar las tareas, lo que hace más fácil de comprender en qué momento se van a ejecutar una serie de operaciones específicas.
Consideré que el conjunto de funciones previamente definidas no es tan amplio como el de \textit{Spark} (aunque ha crecido con el tiempo) y no implementa todas las de \textit{Pandas}, por lo que el uso de \texttt{udfs} puede ser más frecuente que con \textit{Spark} y más demandante de tiempo. Este fue el caso de la función \texttt{rollup} utilizada frecuentemente en este trabajo que ya está definida en \textit{Spark} pero no en \textit{Dask}. Sin embargo, una vez definidas dichas funciones, su ejecución en \textit{Dask} puede ser muy eficiente a pesar de estar definida por el usuario. Una vez dicho lo anterior, no se puede dejar de mencionar que \textit{Dask} también cuenta con funciones que no están implementadas en \textit{Spark} y que pueden acelerar significativamente la ejecución. Un ejemplo es la función \texttt{nsmallest} que es mucho más rápida que su equivalente en \textit{Spark}. También me resultó interesante que el tratamiento de datos fue más complicado que en \textit{Spark}, ya que me encontré con más errores debido a datos que no cumplían con el esquema y con mayores retos para localizar valores nulos.
En cuánto a la lectura de distintos tipos de archivos y sistemas de archivos, \textit{Dask} puede requerir de paquetes adicionales como \texttt{libhdfs3}, \texttt{pymysql} y \texttt{pyarrow} para leerlos y en algunos casos, como el de leer de fuentes como \textit{Azure Blob Storage}, las bibliotecas necesarias siguen en desarrollo, lo cual puede ser una desventaja para casos de uso más específicos.

\subsection{Conclusiones sobre el uso}
En conclusión, considero que una vez que los usuarios se familiarizan, cualquiera de los dos \textit{frameworks} es fácil de usar y ambos tienen capacidades comparables para resolver un gran espectro de problemas. Sin embargo, pienso que el uso de \textit{Dask} es más sencillo que el de \textit{Spark}, tanto para usuarios experimentados como para los nuevos, debido a su similitud con herramientas existentes y a la integración que tiene con las mismas. No obstante, también creo que \textit{Spark} tiene ventajas importantes como el uso de \textit{SQL}, su flexibilidad para leer y escribir a distintas fuentes y la facilidad de trabajar con datos ``sucios'' que pueden facilitar tareas más complejas.

\section{Documentación}

Durante el uso de cualquiera de los dos \textit{frameworks} la documentación disponible para cada uno es de suma importancia por lo que decidí incluir un breve balance de lo que ofrecen.

\subsection{Documentación de \textit{Spark}}

La documentación de \textit{Spark} es muy especializada y contiene mucha información que puede ser poco relevante para usuarios nuevos pero resulta útil para usuarios más avanzados. Este carácter tan especializado puede abrumar y hacer la información difícil de consultar, aunque también cuenta con secciones introductorias que son útiles para iniciar. También consideré que el formato no es tan amigable y no siempre es sencillo encontrar la información dentro de las distintas secciones, por lo que en muchos casos opté por buscar la información en otros medios. Además, la información sobre qué hacen las funciones y parámetros de la herramienta es clara, pero no así cómo usarlas, debido a que las descripciones no son siempre seguidas de ejemplos o de los argumentos que pueden llevar, lo que complica el uso de las mismas.

\subsection{Documentación de \textit{Dask}}

La documentación de \textit{Dask} me pareció más intuitiva y fácil de seguir y consultar, ya que contiene ejemplos simples y claros acompañados de secciones concretas y material interactivo como videos y recursos adicionales cuyo objetivo no es crear expertos sino introducir al uso de la herramienta. Este carácter más general e introductorio hace que la documentación se quede corta cuando el usuario se enfrenta a problemas más específicos. También es importante mencionar que el formato es similar al de \textit{Pandas}, lo que la hace fácilmente navegable para usuarios de esta biblioteca.
La información de funciones específicas es clara y fácil de consultar, lo que facilita mucho el uso de la herramienta. Además, otra sección que se agradece es la de errores comunes, ya que los usuarios tienen un área estructurada y bien explicada de los problemas más frecuentes y su solución. Por último, creo que en casos más específicos como el uso de \texttt{distribuited} y \texttt{dask-yarn} la información es clara pero se queda corta cuando se quiere avanzar más en el uso de estas extensiones de \textit{Dask}, lo que obliga a buscar información en otros medios como foros o artículos independientes.

\subsection{Conclusiones sobre la documentación}

En conclusión, creo que ambas documentaciones tienen información relevante pero la de \textit{Dask} es más fácil de comprender, aunque en ambos casos pienso que es necesario acudir a recursos adicionales como libros y foros, en el caso de \textit{Dask} por que la documentación puede ser insuficiente para algunos casos de uso y en el caso de \textit{Spark} por qué esta no es fácil de navegar y en ocasiones la gran cantidad de información puede ser abrumadora.


\section{Comunidad}

Una de las grandes ventajas de usar herramientas de código abierto es que cualquier persona puede usarlas y colaborar, además de que ofrecen una gran red de apoyo para resolución de problemas. \textit{Dask} y \textit{Spark} no son la excepción, por lo que en los siguientes párrafos expondré los aspectos que consideré más relevantes para comparar la comunidad de cada uno.

La comunidad de \textit{Spark} es mucho más grande que la de \textit{Dask} y esto se puede ver en el número de contribuidores en \textit{GitHub}, que son 1,687 para \textit{Spark} \cite{repo-spark} y 438 para \textit{Dask} \cite{repo-dask}, y el número de preguntas en \textit{Stack Overflow} (obtenidas de \cite{stackoverflow-stats}), donde podemos ver que durante cada mes del último año más del 0.30\% de las preguntas han utilizado el tag \texttt{pyspark}, mientras que la cifra para el tag \texttt{dask} es inferior al 0.07\%, y aunque en ambos casos la popularidad del \textit{framework} se ha incrementado con el tiempo, el crecimiento del tag \texttt{pyspark} ha sido mayor. Las cifras anteriores son un buen indicador de que la comunidad de \textit{Spark} es más activa y más grande, lo que puede facilitar la resolución de dudas o encontrar soluciones a problemas que otros usuarios se han encontrado. Como ejemplo, durante la realización de este trabajo, todas las dudas que me resultaron sobre \textit{Spark} fueron resueltas con respuestas existentes de \textit{Stack Overflow} y otros foros o con documentación y artículos existentes, mientras que con \textit{Dask} tuve que hacer dos preguntas nuevas en \textit{Stack Overflow} y abrir un \textit{issue} en \textit{GitHub} para resolver algunos de los problemas que enfrenté y cuya solución no pude encontrar en los recursos existentes. No obstante, una de las preguntas y el \textit{issue} de \textit{GitHub} fueron resueltos en menos de 12 horas, por lo que me permito suponer que aunque la comunidad no es tan grande como la de \textit{Spark}, definitivamente es activa y seguirá creciendo. 

En conclusión, creo que sí es más fácil obtener ayuda de la comunidad y recursos ya existentes al enfrentarse a problemas de \textit{Spark}, pero también la de \textit{Dask} puede ofrecer mucha ayuda, aunque haya que buscar más o esperar un poco más de tiempo.

\section{Portal de usuario}

Ambas herramientas cuentan con un portal de usuario en la que se puede monitorear el estado de las tareas y los ejecutores o \textit{workers} encargados de su realización. Sin embargo, aunque cumplen tareas similares tienen diferencias importantes que expondré en los siguientes párrafos.

\subsection{Portal de usuario de \textit{Spark}}

El portal de \textit{Spark} ofrece más información, esta va desde la ejecución actual del trabajo hasta descripciones del ambiente en el que se están realizando las tareas. No obstante, creo que tanta información puede llegar a ser abrumadora y dificulta encontrar información importante como la memoria disponible por ejecutor y para el \textit{driver}. \textit{Spark} ofrece una representación gráfica del plan de ejecución limpia y general, lo que simplifica ver los distintos pasos de los cuales consiste la aplicación y el avance actual. El estado de tareas específicas y su avance se representa en una tabla que se actualiza con baja frecuencia y que puede resultar difícil de leer. Además, los nombres que describen las tareas no siempre son fáciles de entender.

\subsection{Portal de usuario de \textit{Dask}}

El portal de usuario de \textit{Dask} tiene gráficas de barras y barras de avance que son fáciles de leer y que permiten monitorear el uso de memoria y \textit{CPU} en tiempo real, así como el avance de las tareas que están en ejecución. \textit{Dask} representa el plan de ejecución mediante una gráfica en la que cada nodo es una acción sobre una partición, lo cuál puede ser útil para pocas particiones, pero se vuelve muy complicada de leer cuando el número de estas es muy grande y en algunos casos incluso desaparece debido a que tantos nodos no pueden ser representados. El nombre que \textit{Dask} usa para describir cada tarea me parece más fácil de entender ya que tiene muchas similitudes con el nombre de la función en \textit{Python} y esto ayuda a identificar fácilmente qué acciones del plan de trabajo se deben atender.

\subsection{Conclusiones sobre el portal de usuario}

En resumen, pienso que las mayores ventajas del portal de \textit{Spark} son su representación clara del plan de ejecución y una amplia descripción del ambiente. Por otro lado, creo que la descripción clara de las operaciones que usa \textit{Dask} en el portal de usuario, sumadas a su útil representación del estado de los recursos lo vuelve más útil para monitorear y optimizar los procesos, además de que es más fácil de entender para usuarios inexpertos.


\section{Parametrización de trabajos}

Definir de manera adecuada los parámetros necesarios para la ejecución de un trabajo puede tener un impacto importante en el desempeño de la misma, por lo que la facilidad para realizar este proceso es de gran importancia. A continuación se presenta un balance de las herramientas en este aspecto.

\subsection{Parametrización de trabajos de \textit{Spark}}

\textit{Spark} es mucho más personalizable y cuenta, gracias a su documentación y también a la comunidad, con múltiples ``reglas de dedo'' y recomendaciones que ayudan a alcanzar configuraciones que aprovechan mejor los recursos. Además, cada tarea se puede configurar de forma distinta dependiendo de los datos, la memoria disponible, la fuente o destino de los datos, etc. Sin embargo, esta libertad para personalizar la configuración puede hacer más difícil la configuración de tareas y resultar en ejecuciones que no aprovechan bien los recursos, lo cuál puede ser una gran desventaja.

\subsection{Parametrización de trabajos de \textit{Dask}}

En el caso de \textit{Dask}, considero que la configuración es mucho más sencilla ya que está diseñado para determinar los parámetros automáticamente, pero cambiar alguno en específico puede resultar más complicado que en \textit{Spark}. Además, encontrar recomendaciones para los parámetros de \textit{Dask} es significativamente más complicado, pero también innecesario en muchos de los casos, ya que normalmente la configuración predeterminada tiene un muy buen desempeño.

\subsection{Conclusiones sobre la parametrización de trabajos}

En general, considero que \textit{Spark} tiene una capacidad de personalización de los parámetros mayor y que modificarlos es sencillo y hay múltiples fuentes que consultar para hacerlo de la forma correcta. En \textit{Dask} estas recomendaciones pueden ser más complicadas de encontrar, aunque creo que no es muy necesario ya que su configuración automática permite aprovechar los recursos de manera inteligente, por lo que combina facilidad de uso con aprovechamiento de los recursos.

\section{Transición a la nube}

Otro aspecto importante es la facilidad que tiene cada \textit{framework} para pasar de un ambiente local a uno distribuido, que en este caso fue en la nube. Las principales ventajas y desventajas de cada herramienta son las mencionadas en los siguientes párrafos.

\subsection{Transición de \textit{Spark} a la nube}

En el caso de \textit{Spark}, la ventaja más clara es que el proceso de instalación fue muy transparente ya que los proveedores utilizados durante la implementación cuentan con servicios que se encargan de proveer un ambiente de \textit{Spark} con características especificadas por el usuario (\textit{Microsoft Azure HDInsight}, \textit{AWS EMR} y \textit{IBM Cloud Watson Studio}). Gracias a estos servicios, pasar a la nube fue muy sencillo, con la única desventaja de que una vez creado el ambiente, este puede ser difícil de personalizar. Los dos ejemplos más claros de este problema fueron la imposibilidad de cambiar fácilmente la versión de \textit{Python}, por lo que el código tuvo que ser ligeramente modificado ya que en el ambiente local estaba escrito en \textit{Python} \texttt{3.6} y la versión de los servidores era la \texttt{2.7} (esto no fue problema en \textit{Watson Studio} ya que permite elegir la versión de \textit{Python}). Sin embargo, los cambios necesarios no tomaron más de un día. El segundo ejemplo es que para utilizar algunos de los parámetros de ejecución de \textit{Spark} mencionados en \ref{section:parametrizacion_de_trabajos_spark}, fue necesario cambiar la configuración de \textit{Hadoop}, lo cuál no fue sencillo y se realizó mediante un \textit{step} en \textit{AWS}. A pesar de esto, considero que la fácil instalación y uso en la nube supera la desventaja de difícil personalización del ambiente.

\subsection{Transición de \textit{Dask} a la nube}

En el caso de \textit{Dask}, la primera desventaja fue que la tarea de instalación es más complicada, ya que desde el desarrollo existieron diversos problemas con la instalación en \textit{IBM Cloud Watson Studio} (lo que llevó a abandonar las pruebas con este proveedor de nube). Más adelante, durante la instalación de \texttt{dask-yarn} existieron problemas de falta de sincronía de versiones en múltiples paquetes y fue necesario utilizar tanto \texttt{conda} como \texttt{pip} para lograr que los distintos paquetes coincidieran. El problema más grande, que involucró la instalación de \texttt{distributed} y \texttt{dask-yarn}, fue resuelto rápidamente al abrir un \textit{issue} (ver \cite{issue-dask-yarn}) con el equipo de \textit{Dask} que respondió rápidamente. Después de la instalación exitosa, hubo problemas de asignación de recursos de \textit{YARN} a \textit{Dask} (esto sucedió en ambos servicios de la nube y el problema se puede consultar en \cite{q-dask-yarn}), lo que provocaba que los \texttt{dask-workers} se iniciaran sin memoria y que las tareas fracasaran de forma inmediata y que, en última instancia, se tuviera que optar por el método ``difícil'' sugerido en la documentación oficial de \textit{Dask} (ver \cite{daskdistributedsetup}). Este método me pareció muy amigable y fácil de implementar. No obstante, esta alternativa usa el \textit{scheduler} nativo de \textit{Dask} y no se integra con \textit{YARN}, lo que puede ser un gran incoveniente en un ambiente con múltiples usuarios y procesos en ejecución. Después de obtener la combinación de bibliotecas que funcionaba, replicar el ambiente se vuelve más sencillo y se puede automatizar mediante un archivo \texttt{bash} y un proceso \textit{Bootstrap} en \textit{AWS EMR}. Sin embargo, a diferencia de \textit{Spark}, \textit{Dask} requiere que los \texttt{dask-worker} y el \texttt{dask-scheduler} sean iniciados manualmente; este proceso es rápido y sólo se debe hacer cuando se configuran los nodos del ambiente distribuido, por lo que no lo consideré un gran inconveniente. Una vez realizado esto, la conexión a los nodos se puede hacer mediante el código que se va a ejecutar y se pueden personalizar los parámetros fácilmente dentro del mismo. En conclusión, creo que una vez realizada la configuración necesaria la primera vez, esta es fácil y rápida de replicar, pero también considero que la primera vez que se realiza el proceso puede ser complicada para usuarios nuevos. 

\subsection{Conclusiones sobre la transición a la nube}

En resumen, considero que el pase al ambiente distribuido es más sencillo en \textit{Spark} debido principalmente a que ya existen servicios de nube que automatizan el proceso de instalación, pero que hacen la personalización del ambiente más difícil. En el caso de \textit{Dask}, la ventaja más grande es que se puede utilizar fácilmente un ambiente muy personalizado. Sin embargo, el uso de múltiples paquetes puede traer problemas de incompatibilidad que puede llevar consigo dificultades importantes para la instalación. Por último, creo que la mayor desventaja es que la integración con \textit{YARN} aún no es tan sencilla y esto dificulta la administración del ambiente, por lo que \textit{Spark} es mejor para el pase al ambiente distribuido. 
