%----------------------------------------------------------------------------------------
%	PREÁMBULO
%----------------------------------------------------------------------------------------

\documentclass[11pt, oneside]{book}
\usepackage[paperwidth=17cm, paperheight=22.5cm, bottom=2.5cm, right=2.5cm]{geometry}

% El borde inferior puede parecerles muy amplio a la vista. Les recomiendo hacer una prueba de impresión antes para ajustarlo

\usepackage{amssymb,amsmath,amsthm} % Símbolos matemáticos
\usepackage[spanish]{babel}
\usepackage[utf8]{inputenc} % Acentos y otros símbolos 
\usepackage{enumerate}
\usepackage{float}% http://ctan.org/pkg/float
\usepackage{hyperref} % Hipervínculos en el índice
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
%\usepackage{subfig} % Subfiguras
\graphicspath{{Imagenes/}} % En qué carpeta están las imágenes

% Para eliminar guiones y justificar texto
\tolerance=1
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000

\linespread{1.25} % Asemeja el interlineado 1.5 de Word

\let\oldfootnote\footnote % Deja espacio entre el número del pie de página y el inicio del texto
\renewcommand\footnote[1]{%
\oldfootnote{\hspace{0.05mm}#1}}

\renewcommand{\thefootnote} {\textcolor{Black}{\arabic{footnote}}} % Súperindice a color negro

\setlength{\footnotesep}{0.75\baselineskip} % Espaciado entre notas al pie

\usepackage{fnpos} % Footnotes al final de pág.

\usepackage[justification=centering, font=bf, labelsep=period, skip=5pt, font=footnotesize]{caption} % Centrar captions de tablas y ponerlas en negritas
\usepackage{caption}
% \captionsetup{font=footnotesize}

\newcommand{\imagesource}[1]{{\footnotesize Fuente: #1}}

\usepackage{tabularx} % Big tables
\usepackage{graphicx}
\usepackage{adjustbox}
\usepackage{longtable}

\usepackage{float} % Float tables

\usepackage[usenames,dvipsnames]{xcolor} % Color
\usepackage{pgfplots} % Gráficas
\pgfplotsset{compat=newest}
\pgfplotsset{width=7.5cm}
\pgfkeys{/pgf/number format/1000 sep={}}

\begin{document}

%----------------------------------------------------------------------------------------
%	PORTADA
%----------------------------------------------------------------------------------------

\title{Confianza institucional, inclusión social, intensidad religiosa y percepción tecnológica como factores de innovación para el crecimiento económico} % Con este nombre se guardará el proyecto en writeLaTex

\begin{titlepage}
\begin{center}

\textsc{\Large Instituto Tecnológico Autónomo de México}\\[2em]

%Figura
\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.50]{itam_logo.png}
\end{center}
\end{figure}

% Pueden modificar el tamaño del logo cambiando la escala

\textbf{\LARGE Comparación de Dask y Spark en el procesamiento de grandes volúmenes de datos}\\[2em]

\textsc{\large Tesis}\\[1em]

\textsc{\large que para obtener el título de}\\[1em]

\textsc{\LARGE Licenciado en Matemáticas Aplicadas}\\[1em]

\textsc{\large Presenta}\\[1em]

\textsc{\LARGE Iker Antonio Olarra Maldonado}\\[1em]

\textsc{\large Asesora}\\[1em]

\textsc{\LARGE Mtra. Liliana Millán}\\[2em]

% Asegúrense de escribir el nombre completo de su asesor

\end{center}

\vspace*{\fill}
\textsc{Ciudad de México \hspace*{\fill} 2021}

\end{titlepage}

%----------------------------------------------------------------------------------------
%	DECLARACIÓN
%----------------------------------------------------------------------------------------

\thispagestyle{empty}

\vspace*{\fill}
\begingroup

\noindent
«Con fundamento en los artículos 21 y 27 de la Ley Federal del Derecho de Autor y como titular de los derechos moral y patrimonial de la obra titulada ``\textbf{Comparación de Dask y Spark en procesamiento de grandes volúmenes de datos}'', otorgo de manera gratuita y permanente al Instituto Tecnológico Autónomo de México y a la Biblioteca Raúl Bailléres Jr., la autorización para que fijen la obra en cualquier medio, incluido el electrónico, y la divulguen entre sus usuarios, profesores, estudiantes o terceras personas, sin que pueda percibir por tal divulgación una contraprestación.»

% Asegúrense de cambiar el título de su tesis en el párrafo anterior

\centering 

\vspace{5em}

\rule[1em]{20em}{0.5pt} % Línea para la fecha

\textsc{Fecha}
 
\vspace{8em}

\rule[1em]{20em}{0.5pt} % Línea para la firma

\textsc{Iker Antonio Olarra Maldonado}

\endgroup
\vspace*{\fill}

%----------------------------------------------------------------------------------------
%	DEDICATORIA
%----------------------------------------------------------------------------------------

\pagestyle{plain}
\frontmatter

\chapter*{}
\begin{flushright}
\textit{Para Antonio, Epigmenio, Rosario y Soledad.}
\end{flushright}

%----------------------------------------------------------------------------------------
%	AGRADECIMIENTOS
%----------------------------------------------------------------------------------------

\chapter*{Agradecimientos}

\noindent A Antonio y Lorena, por ser mis modelos a seguir y a Aitana, por ser mi mejor amiga.

% Esta sección es lo único que la gente lee. True story :)

%----------------------------------------------------------------------------------------
%	RESUMEN
%----------------------------------------------------------------------------------------

\chapter*{Resumen}

\noindent El volumen de datos y las capacidades de almacenamiento han aumentado de forma considerable en las últimas décadas. Esto ha incrementado la necesidad de desarrollar \textit{software} de procesamiento de datos que utilice cómputo en paralelo y distribuido para poder procesar los conjuntos masivos de datos creados diariamente. Dos de las herramientas de código abierto más populares para el desarrollo de aplicaciones de ciencia de datos y de ejecución de algoritmos distribuidos son \textit{Dask} y \textit{Spark}. En esta investigación se realizó un total de 14,280 ejecuciones divididas en 8 procesos y en muestras del conjunto de datos \textit{Reporting Carrier On-Time Performance (1987-present)} de 43 GB que involucraron operaciones como cálculo de agregaciones, obtención de estadísticas, preparación de datos, escritura de resultados a bases de datos y archivos \texttt{parquet} y un algoritmo iterativo de ruta mínima, con el objetivo de compararlos. Estos procesos fueron ejecutados en un ambiente local en modo \textit{standalone} y en un ambiente distribuido en la nube con un nodo \textit{head} y tres nodos \textit{worker}.

Los resultados mostraron que cuando la muestra de datos es de un millón de datos o menor, \textit{Dask} tiene un desempeño superior, ya combina tiempos de ejecución cortos, poca variación, 
escritura rápida, menor tiempo de inicio de la ejecución, un cómputo más veloz de los resultados y gran estabilidad. Por otro lado, para muestras mayores, \textit{Spark} fue superior tres aspectos: primero, en la ejecución de agregaciones más complejas que involucraban la creación de una nueva llave y agregaciones utilizándola, segundo, en la escritura a \textit{MySQL} donde registró menores tiempos que \textit{Dask} cuando los resultados eran de aproximadamente 500,000 registros o mayores, y tercero, fue más robusto ya que completó un mayor porcentaje de las ejecuciones que \textit{Dask}. Por otro lado, \textit{Dask} mantuvo un mejor desempeño en los otros rubros y mostró una velocidad mucho mayor en la escritura de archivos \texttt{parquet}, en la ejecución del algoritmo iterativo gracias a un mejor manejo de la memoria, en el cálculo de agregaciones como máximos, mínimos y promedios y en tareas de preparación de datos como eliminación de valores nulos. Adicionalmente, la ejecución de los procesos mostró una gran importancia de la capacidad de escritura, ya que esta muchas veces fue decisiva para hacer que un \textit{framework} completara un proceso más rápidamente que el otro. Además, se identificó una tendencia a que la brecha de tiempo entre ambos \textit{frameworks}, que casi siempre fue favorable a \textit{Dask}, se redujera conforme aumentaba el número de registros procesados, por lo que parece que \textit{Spark} se vuelve más competitivo conforme el tamaño del conjunto de datos aumenta.

Por otro lado, en cuánto a la facilidad de implementación y de adopción de las herramientas, \textit{Dask} resultó más sencillo de instalar, empezar a utilizar y de integrar con herramientas de \textit{Python} existente. Además la documentación clara y concisa, su comunidad pequeña pero activa, un portal de usuario intuitivo y su parametrización automática fueron ventajas que la convierten en una herramienta fácil de adoptar y utilizar, sin embargo, tiene desventajas como su inestabilidad y su necesidad de paquetes adicionales para resolver casos de uso comunes. \textit{Spark}, por otra parte, resultó ser más difícil de adoptar aunque tiene una similitud importante con \textit{SQL} lo que lo convierte en una herramienta útil para solver tareas de este tipo. Además, su gran repertorio de funciones y su integración con otras soluciones y con servicios de nube la vuelven una herramienta versátil y competitiva, no obstante, tiene desventajas como su gran libertad para la parametrización y su API poco familiar que pueden convertirla en una herramienta más difícil de adoptar.

Por último, se considera que ampliar este análisis a herramientas convencionales como \textit{Pandas}, así como un mayor enfoque en la escritura, un mayor desglose de los procesos y hacer pruebas con una mayor cantidad de datos y recursos de infraestructura puede ser de gran utilidad para entender mejor cada \textit{framework} en el futuro e intentar resolver algunas de las preguntas que aparecieron durante la investigación.

\pagestyle{plain}

\noindent 

%----------------------------------------------------------------------------------------
%	Summary
%----------------------------------------------------------------------------------------

\chapter*{Summary}

\noindent Data volume and storage capabilities have increased considerably during the past decades. This has increased the need to develop data processing software which uses distributed and parallel computing to process the massive datasets created daily. Two of the most popular open-source tools for the development of data science and distributed algorithm execution are \textit{Dask} and \textit{Spark}. This investigation consisted of 14,280 executions divided in 8 processes and samples of the 43 GB dataset \textit{Reporting Carrier On-Time Performance (1987-present)} which involved computing aggregations, calculating statistics, data preparation tasks, writting results to data bases and \texttt{parquet} files and an iterative shortest-path algorithm in order to compare both frameworks. The processes were executed in a local environment in standalone mode and in a distributed environment in the cloud with one head node and three worker nodes.

The results showed that when the sample size is smaller than one million records, \textit{Dask} has a better performance, as it combines short execution times, low variation, fast writting, low start time, faster computation of the results and great stability. On the other hand, for larger sample sizes, \textit{Spark} was superior in three aspects: first, on the execution of more complex aggregations involving the creation of a new key, secondly, when writting results to \textit{MySQL} where it achieved lower times when writting more than 500,000 records, and finally, it was more robust as it achieved a greater percentage of completed executions than \textit{Dask}. On the other hand, \textit{Dask} obtained greater performance on the other aspects and showed faster writting to \texttt{parquet} files, a better execution of the iterative algorithm due to superior memory management, lower completion times for aggregation processes involving obtaining maximum, minimum and average values and also in data preparation processes such as eliminating null values. Additionaly, the execution of the processes showed the great importance of writting capabilities, as this was often a decisive factor for a framework to be faster than the other. On top of that, it was identified that the gap of time between both frameworks, which was often favorable to \textit{Dask}, tended to close as the sample size increased, which suggests that \textit{Spark} becomes more competitive when the dataset is larger.

Moving on, regarding the simplicity of implementation and an easy adoption of a framework, \textit{Dask} resulted simpler to install, start using and to integrate with existing \textit{Python} tools. Additionaly, the clear and concise documentation, its small but active community, the intuitive user portal and its automatic parametrization were advantages which make it a easy to use and adopt tool, however, it has disadvantages such as its inestability and its necessity of additional packages to solve common use cases. \textit{Spark}, on the other hand, turned out to be harder to adopt although it has important similarities with \textit{SQL}, which makes it a great tool to solve such tasks. Additionally, its great collection of functions and its close integration with other popular solutions and cloud services make it a versitile and competitive tool, nevertheless, it has disadvantages such as its great freedom to define parameters and an unfamiliar API which can difficult its use.

Lastly, it was suggested to widen the scope of this investigation in the future and incluide other tools such as \textit{Pandas}, increase the focus on writting, have a greater understanding of the parts of each process and make tests with larger datasets and greater infrestructure in order to achieve greater understanding of the \textit{frameworks} and solve some of the questions which arose during the investigation.


\pagestyle{plain}

\noindent 

%----------------------------------------------------------------------------------------
%	TABLA DE CONTENIDOS
%---------------------------------------------------------------------------------------

\tableofcontents

%----------------------------------------------------------------------------------------
%	ÍNDICE DE CUADROS Y FIGURAS
%---------------------------------------------------------------------------------------

\listoftables

\listoffigures

%----------------------------------------------------------------------------------------
%	TESIS
%----------------------------------------------------------------------------------------

\mainmatter % Empieza la numeración de las páginas

\pagestyle{plain}

% Incluye los capítulos en el fólder de capítulos

\include{Chapters/0.Intro}

\include{Chapters/1.Rev}

\include{Chapters/2.MarcoT}

\include{Chapters/3.Metod}

\include{Chapters/4.Res}

\include{Chapters/5.ExpImp}

\include{Chapters/6.Conc}


%----------------------------------------------------------------------------------------
%	APÉNDICES
%----------------------------------------------------------------------------------------

\begin{appendix}

\include{Apendices/ApA}

\end{appendix}

%----------------------------------------------------------------------------------------
%	BIBLIOGRAFÍA
%----------------------------------------------------------------------------------------


\chapter*{Referencias}
\addcontentsline{toc}{chapter}{Referencias}

% Macro. Esto es muy importante, no lo borren

\makeatletter
\renewenvironment{thebibliography}[1]
     {\@mkboth{\MakeUppercase\refname}{\MakeUppercase\refname}%
      \list{}%
           {\setlength{\labelwidth}{0pt}%
            \setlength{\labelsep}{0pt}%
            \setlength{\leftmargin}{\parindent}%
            \setlength{\itemindent}{-\parindent}%
            \@openbib@code
            \usecounter{enumiv}}%
      \sloppy
      \clubpenalty4000
      \@clubpenalty \clubpenalty
      \widowpenalty4000%
      \sfcode`\.\@m}
     {\def\@noitemerr
       {\@latex@warning{Empty `thebibliography' environment}}%
      \endlist}
\makeatother

\begin{thebibliography}{111}

% Lista

% La manera recomendada para citar papers o libros en el formato de Chicago esta en el siguiente vínculo: https://www.chicagomanualofstyle.org/tools_citationguide/citation-guide-2.html

% Es importante poner el apellido del autor seguido del año de publicación, una coma y las páginas consultadas en el texto antes de puntuar y entre paréntesis para las citas en el cuerpo de la tesis

% Ejemplo:

% Las \textit{causas próximas} del crecimiento son conocidas: tecnología, capital humano y físico. La pregunta es ¿por qué unos países sí tienen estas causas próximas y otros no? La respuesta son las \textit{causas fundamentales:} suerte, geografía, cultura e instituciones (Acemoglu 2009, 110).

%AAAAA

% Contexto
\bibitem{seagate} Reinsel, D., Gantz, J., \&; Rydning, J. (2017, April). Data Age 2025: The Evolution of Data to Life-Critical . IDC: Analyze the future. \url{https://www.import.io/wp-content/uploads/2017/04/Seagate-WP-DataAge2025-March-2017.pdf}. 

% Datos
\bibitem{linktranstat} On-Time : Reporting Carrier On-Time Performance (1987-present), \url{https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ}

% Dijkstra
\bibitem{dijkstraexplicado} Boardman, S. (2014). Shortest path problem (Dijkstra’s algorithm). Retrieved from \url{https://www.pearsonschoolsandfecolleges.co.uk/secondary/Mathematics/16plus/AdvancingMathsForAQA2ndEdition/Samples/SampleMaterial/Chp-02\%20023-043.pdf}

\bibitem{dijkstrabellford} Samah W.G. AbuSalim et. al. (2020). Comparative Analysis between Dijkstra and Bellman-Ford Algorithms in Shortest Path Optimization. Retrieved April 05, 2021, from \url{https://iopscience.iop.org/article/10.1088/1757-899X/917/1/012077}

% Parquet
\bibitem{column-oriented} Abadi, D. J., Boncz, P. A., \&; Harizopoulos, S. (n.d.). Column-oriented Database Systems. Paperhub. \url{https://paperhub.s3.amazonaws.com/741f4f9f3201baa76ddf05d3bff631bd.pdf}

\bibitem{columnar-storage-blog} Rathbone, M. (2019, November 21). Beginners Guide to Columnar File Formats in Spark and Hadoop. Matthew Rathbone's Blog. \url{https://blog.matthewrathbone.com/2019/11/21/guide-to-columnar-file-formats.html}

% Caching
\bibitem{aws-caching} Amazon Web Services, Inc. (2021). Caching Overview. Amazon AWS. \url{https://aws.amazon.com/caching/}. 

% Dask
\bibitem{daskdocs} Anaconda Inc. (2018). Dask. Retrieved March 26, 2021, from \url{https://docs.dask.org/en/latest/index.html}

\bibitem{daskpaper} Rocklin, M. (2015). Dask: Parallel Computation with Blocked algorithms and Task Scheduling. Retrieved March 26, 2021, from \url{https://pdfs.semanticscholar.org/73b5/8192f30bb6be8e798084d4481b97124570ed.pdf}

\bibitem{daskoverheads} Böhm, S., \& Beránek, J. (2020, October 21). Runtime vs Scheduler: Analyzing Dask’s Overheads. Retrieved March 26, 2021, from \url{https://arxiv.org/pdf/2010.11105.pdf}

\bibitem{daskscheduling} Anaconda Inc. (2018). Scheduling. Retrieved March 26, 2021, from \url{https://docs.dask.org/en/latest/scheduling.html}

\bibitem{daskdistributed} Anaconda Inc. (2016). Dask.distributed. Retrieved March 26, 2021, from \url{https://distributed.dask.org/en/latest/}

\bibitem{daskdistributedsetup} Anaconda Inc. (n.d.). Quickstart. Dask.distributed 2021.05.1+2.g9d4f0bf2 documentation. \url{https://distributed.dask.org/en/latest/quickstart.html#setup-dask-distributed-the-hard-way}. 

\bibitem{daskdataframe} Anaconda Inc. (2018). DataFrame. Retrieved April 02, 2021, from \url{https://docs.dask.org/en/latest/dataframe.html}

\bibitem{daskbestpractices} Dask - Best Practices, \url{https://docs.dask.org/en/latest/dataframe-best-practices.html}

% Spark
\bibitem{sparkberkeley} Zahaira, M., Xin, R. S., Wendell, P., Das, T., Ambrust, M., Dave, A., . . . Stoica, I. (2016, November). Apache Spark: A Unified Engine for Big Data Processing. Retrieved March 24, 2021, from \url{https://people.eecs.berkeley.edu/~alig/papers/spark-cacm.pdf}

\bibitem{sparkhardware} Apache Foundation. (n.d.). Hardware Provisioning. Hardware Provisioning - Spark 2.4.0 Documentation. \url{https://spark.apache.org/docs/2.4.0/hardware-provisioning.html}.

\bibitem{sparkconfcloudera} Cloudera. (2021, January 21). How-to: Tune Your Apache Spark Jobs (Part 2). Cloudera Blog. \url{https://blog.cloudera.com/how-to-tune-your-apache-spark-jobs-part-2/}. 

\bibitem{sparkconfuds} Rao, S. (2020, April 21). Spark performance tuning guidelines. Unified Data Sciences (Big Data). \url{https://www.unifieddatascience.com/spark-performance-tuning-guidelines}. 

\bibitem{sparkibm} Kambhampati, S. (2020, June 30). Explore best practices for Spark performance optimization. Retrieved March 26, 2021, from \url{https://developer.ibm.com/technologies/artificial-intelligence/blogs/spark-performance-optimization-guidelines/}

\bibitem{sparkguide} Chambers, B. \& Zaharia, M. (2018). Spark: The definitive guide. Beijing: O'Reilly.

\bibitem{sparkclusteroverview} Cluster mode overview. (n.d.). Retrieved March 24, 2021, from \url{https://spark.apache.org/docs/2.4.0/cluster-overview.html}


% Datos comunidad dask y spark
\bibitem{repo-dask} Dask. (n.d.). dask/dask. GitHub. \url{https://github.com/dask/dask}.

\bibitem{repo-spark} Apache, Spark. (n.d.). apache/spark. GitHub. \url{https://github.com/apache/spark}.

\bibitem{stackoverflow-stats} Stack Overflow. (n.d.). Stack Overflow Trends. Stack Overflow Insights - Developer Hiring, Marketing, and User Research. \url{https://insights.stackoverflow.com/trends?tags=dask\%2Cpyspark\%2Capache-spark}.   

% AWS
\bibitem{ec2-instances} Amazon Web Services Inc. (n.d.). Amazon EC2 Instance Types.  \url{https://aws.amazon.com/ec2/instance-types/}.

% Comparacion Spark - Dask
\bibitem{comparative-evolution} Mehta, P., Dorkenwald, S., Zhao, D., Kaftan, T., Cheung, A., Balazinska, M., Rokem, A., Connolly, A., Vanderplas, J.,  \& AlSayyad, Y. (n.d.). Comparative Evaluation of Big-Data Systems on Scientific Image Analytics Workloads. University of Washington Computer Science \& Engineering community. \url{https://homes.cs.washington.edu/~magda/papers/mehta-vldb17.pdf}. 

\bibitem{dask-spark-neuroimaging} Dugré, M., Hayot-Sasson, V., \& Glatard, T. (2019, October 5). A performance comparison of Dask and Apache Spark for data-intensive neuroimaging pipelines. Arxiv. \url{https://arxiv.org/pdf/1907.13030.pdf}.

\bibitem{koalas-dask} Meng, X., \& Kwon, H. (2021, April 8). How fast Koalas and PySpark are compared to Dask - The Databricks Blog. Databricks. \url{https://databricks.com/blog/2021/04/07/benchmark-koalas-pyspark-and-dask.html}. 

% Repo de git
\bibitem{compara-resultados} Olarra, I. (2021). Proceso de revisión de equivalencia de resultados. Spark - Rita. \url{https://github.com/ikerforce/spark-rita/blob/master/results/revision_equivalencia_resultados.py}. 

\bibitem{proceso-muestreo} Olarra, I. (2021). Proceso de obtención de muestras de datos. Spark - Rita. \url{https://github.com/ikerforce/spark-rita/blob/master/src/muestreo_spark.py}.

\bibitem{tratamiento-datos} Olarra, I. (2021). Proceso de preparación de datos. Spark - Rita. \url{https://github.com/ikerforce/spark-rita/tree/master/src/preprocessing}.

\bibitem{issue-dask-yarn} Olarra, I. (2020, April 28). dask-yarn job fails with dumps\_msgpack ImportError · Issue \#147 · dask/dask-yarn. GitHub - Dask. \url{https://github.com/dask/dask-yarn/issues/147}. 

% Preguntas Stack-Overflow 
\bibitem{q-dask-yarn} Olarra, I. (1969, November 1). dask-yarn script fails with distributed.scheduler.KilledWorker and empty workers. Stack Overflow. \url{https://stackoverflow.com/questions/67326749/dask-yarn-script-fails-with-distributed-scheduler-}\ \url{killedworker-and-empty-workers}. 


%BBBBB

%CCCCC

%DDDDD

%EEEEE

%FFFFF

%GGGGG

%HHHHH

%IIIII

%JJJJJ

%KKKKK

%LLLLL

%MMMMM

%NNNNN

%OOOOO

%PPPPP

%QQQQQ

%RRRRR

%SSSSS

%TTTTT

%UUUUU

%VVVVV

%WWWWW

%XXXXX

%YYYYY

%ZZZZZ

\end{thebibliography}

\newpage
\thispagestyle{empty}
\begin{table}[p]
\centering
\small
\label{ed}
\begin{tabular}{c}
\textit{Comparación de Dask y Spark en} \\ \textit{procesamiento de grandes volúmenes de datos,}\\ escrito por Iker Olarra,\\ se terminó de imprimir en agosto de 2021\\ en los talleres de Tesis Matozo.\\ Campeche 156, colonia Roma,\\ Ciudad de México.
\end{tabular}
\end{table}

% Si lo prefieren, avisen a su taller que esta página ya la incluyeron ustedes para que no les impriman las que ellos usan. Lo recomiendo ampliamente

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}