Notas:

- Hay que poner la partición de Spark al leer.
- Tengo que cambiar los nombres de la agregación por ruta.


To do:
- En lugar de hacer la ejecucuón por proceso mejor hacerla por la tabla en la que se escribe.
- Falta en Dask hacer la agregación por MKID


Dask desventajas:
- Es más difícl escribir todos los resultados a MySQL (Hay que borrar para la primera y luego poner append)


Dask parquet:
- Leyendo con pyarrow y usando metadata el tiempo es: 1892.0462560653687 con 80345298 registros.
- Leer, contar, hacer repartition de 4960 a 50 particiones: 1648.80868601799 con 80345298 registros.
- 

Muestras:

Para el experimento utilizaré 5 muestras de los siguientes tamaños:

- 10K: 10,000 registros y 8MB de tamaño.
- 100K: 100,000 registros y 16MB de tamaño.
- 1M: 1,000,000 de registros y 71MB de tamaño.
- 10M: 10,000,000 de registros y 2281MB de tamaño.
- Total: ~80,000,000 de registros y 4774MB de tamaño.

